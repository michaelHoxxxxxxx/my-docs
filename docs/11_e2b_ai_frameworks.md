# E2B AI æ¡†æ¶é›†æˆæŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†å¦‚ä½•å°† E2B ä¸ä¸»æµ AI å¼€å‘æ¡†æ¶é›†æˆï¼ŒåŒ…æ‹¬ LangChainã€LangGraphã€Autogenã€Vercel AI SDK å’Œ AgentKit ç­‰ï¼Œæ„å»ºå¼ºå¤§çš„ AI åº”ç”¨ã€‚

## ğŸ“‹ ç›®å½•

- [LangChain é›†æˆ](#langchain-é›†æˆ)
- [LangGraph å·¥ä½œæµé›†æˆ](#langgraph-å·¥ä½œæµé›†æˆ)
- [Autogen å¤šä»£ç†é›†æˆ](#autogen-å¤šä»£ç†é›†æˆ)
- [Vercel AI SDK é›†æˆ](#vercel-ai-sdk-é›†æˆ)
- [AgentKit ç¼–ç ä»£ç†](#agentkit-ç¼–ç ä»£ç†)
- [æ¡†æ¶å¯¹æ¯”ä¸é€‰æ‹©](#æ¡†æ¶å¯¹æ¯”ä¸é€‰æ‹©)
- [é«˜çº§é›†æˆæ¨¡å¼](#é«˜çº§é›†æˆæ¨¡å¼)

## LangChain é›†æˆ

### æ¦‚è¿°

LangChain æ˜¯æœ€æµè¡Œçš„ LLM åº”ç”¨å¼€å‘æ¡†æ¶ï¼ŒE2B å¯ä»¥ä½œä¸º LangChain çš„å·¥å…·ï¼ˆToolï¼‰é›†æˆï¼Œæä¾›å®‰å…¨çš„ä»£ç æ‰§è¡Œç¯å¢ƒã€‚

### åŸºç¡€é›†æˆ

```python
from langchain.tools import Tool
from langchain.agents import initialize_agent, AgentType
from langchain.chat_models import ChatOpenAI
from e2b_code_interpreter import Sandbox
import json

class E2BTool:
    """E2B ä½œä¸º LangChain å·¥å…·"""
    
    def __init__(self):
        self.sandbox = None
        
    def _ensure_sandbox(self):
        """ç¡®ä¿æ²™ç®±å·²åˆå§‹åŒ–"""
        if not self.sandbox:
            self.sandbox = Sandbox()
    
    def run_code(self, code: str) -> str:
        """æ‰§è¡Œ Python ä»£ç """
        self._ensure_sandbox()
        try:
            result = self.sandbox.run_code(code)
            output = {
                "stdout": result.logs.stdout,
                "stderr": result.logs.stderr,
                "error": result.error,
                "artifacts": [
                    {"name": a.name, "type": a.type} 
                    for a in result.artifacts
                ] if result.artifacts else []
            }
            return json.dumps(output, indent=2)
        except Exception as e:
            return f"Error: {str(e)}"
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.sandbox:
            self.sandbox.kill()

# åˆ›å»º LangChain å·¥å…·
e2b_tool = E2BTool()

# å®šä¹‰å·¥å…·
tools = [
    Tool(
        name="Python Code Interpreter",
        func=e2b_tool.run_code,
        description="""
        Use this tool to execute Python code in a secure sandbox environment.
        Input should be valid Python code.
        The tool will return the output, including stdout, stderr, and any generated files.
        Perfect for data analysis, calculations, and creating visualizations.
        """
    )
]

# åˆå§‹åŒ– LLM å’Œä»£ç†
llm = ChatOpenAI(model="gpt-4", temperature=0)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ä½¿ç”¨ç¤ºä¾‹
response = agent.run("""
åˆ†æè¿™ç»„æ•°æ®å¹¶åˆ›å»ºå¯è§†åŒ–ï¼š
data = [23, 45, 56, 78, 32, 67, 89, 12, 34, 56]
1. è®¡ç®—åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
2. åˆ›å»ºç›´æ–¹å›¾
3. è¯†åˆ«å¼‚å¸¸å€¼
""")

print(response)
```

### é«˜çº§ LangChain é›†æˆ

```python
from langchain.memory import ConversationBufferMemory
from langchain.callbacks import StreamingStdOutCallbackHandler
from langchain.schema import Document
from typing import List, Dict, Any
import asyncio

class AdvancedE2BChain:
    """é«˜çº§ E2B LangChain é›†æˆ"""
    
    def __init__(self, model_name: str = "gpt-4"):
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=0,
            streaming=True,
            callbacks=[StreamingStdOutCallbackHandler()]
        )
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        self.sandbox = None
        self.context_documents: List[Document] = []
        
    async def initialize_sandbox(self):
        """å¼‚æ­¥åˆå§‹åŒ–æ²™ç®±"""
        self.sandbox = await Sandbox.create()
        
        # é¢„è£…å¸¸ç”¨åº“
        setup_code = """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import requests
import json
from datetime import datetime, timedelta
import sqlite3

# è®¾ç½®ç»˜å›¾æ ·å¼
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼")
print("å¯ç”¨åº“: pandas, numpy, matplotlib, seaborn, requests, sqlite3")
"""
        await self.sandbox.run_code(setup_code)
    
    def add_context(self, documents: List[Document]):
        """æ·»åŠ ä¸Šä¸‹æ–‡æ–‡æ¡£"""
        self.context_documents.extend(documents)
    
    async def process_with_context(self, query: str) -> Dict[str, Any]:
        """å¤„ç†å¸¦ä¸Šä¸‹æ–‡çš„æŸ¥è¯¢"""
        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n".join([doc.page_content for doc in self.context_documents])
        
        # åˆ›å»ºå¢å¼ºæç¤º
        enhanced_prompt = f"""
        Context information:
        {context}
        
        User query: {query}
        
        Based on the context, write Python code to answer the query.
        Use the sandbox environment to execute the code.
        """
        
        # ä½¿ç”¨ Chain å¤„ç†
        from langchain.chains import LLMChain
        from langchain.prompts import ChatPromptTemplate
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful AI assistant with access to a Python code interpreter."),
            ("human", "{input}")
        ])
        
        chain = LLMChain(
            llm=self.llm,
            prompt=prompt,
            memory=self.memory
        )
        
        # è·å– LLM å“åº”
        response = await chain.arun(input=enhanced_prompt)
        
        # æå–å¹¶æ‰§è¡Œä»£ç 
        code = self._extract_code(response)
        if code:
            result = await self.sandbox.run_code(code)
            return {
                "response": response,
                "code": code,
                "execution_result": result,
                "context_used": len(self.context_documents)
            }
        
        return {"response": response, "code": None}
    
    def _extract_code(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–ä»£ç """
        import re
        code_blocks = re.findall(r'```python\n(.*?)\n```', text, re.DOTALL)
        return '\n\n'.join(code_blocks) if code_blocks else ""
    
    async def create_rag_pipeline(self, data_source: str):
        """åˆ›å»º RAG (Retrieval-Augmented Generation) ç®¡é“"""
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain.embeddings import OpenAIEmbeddings
        from langchain.vectorstores import FAISS
        
        # åœ¨æ²™ç®±ä¸­å¤„ç†æ•°æ®
        load_code = f"""
# åŠ è½½å’Œå¤„ç†æ•°æ®
import pandas as pd

# å‡è®¾æ˜¯ CSV æ–‡ä»¶
data = pd.read_csv('{data_source}')
print(f"æ•°æ®å½¢çŠ¶: {{data.shape}}")
print(f"åˆ—: {{data.columns.tolist()}}")

# è½¬æ¢ä¸ºæ–‡æœ¬ç”¨äº RAG
text_data = []
for idx, row in data.iterrows():
    text = " | ".join([f"{{col}}: {{row[col]}}" for col in data.columns])
    text_data.append(text)

# ä¿å­˜å¤„ç†åçš„æ–‡æœ¬
with open('/tmp/processed_data.txt', 'w') as f:
    f.write('\\n'.join(text_data))
    
print(f"å¤„ç†äº† {{len(text_data)}} æ¡è®°å½•")
"""
        
        result = await self.sandbox.run_code(load_code)
        
        # ä¸‹è½½å¤„ç†åçš„æ•°æ®
        processed_data = await self.sandbox.download_file('/tmp/processed_data.txt')
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
        documents = text_splitter.create_documents([processed_data])
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.from_documents(documents, embeddings)
        
        return vectorstore
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.sandbox:
            await self.sandbox.kill()

# ä½¿ç”¨ç¤ºä¾‹
async def advanced_langchain_demo():
    chain = AdvancedE2BChain()
    await chain.initialize_sandbox()
    
    # æ·»åŠ ä¸Šä¸‹æ–‡
    chain.add_context([
        Document(page_content="å…¬å¸ 2023 å¹´æ”¶å…¥ä¸º 1000 ä¸‡ç¾å…ƒ"),
        Document(page_content="ä¸»è¦äº§å“åŒ…æ‹¬ AI å·¥å…·å’Œæ•°æ®åˆ†æå¹³å°"),
        Document(page_content="å®¢æˆ·ä¸»è¦åˆ†å¸ƒåœ¨åŒ—ç¾å’Œæ¬§æ´²")
    ])
    
    # å¤„ç†æŸ¥è¯¢
    result = await chain.process_with_context(
        "åŸºäºæä¾›çš„å…¬å¸ä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ªæ”¶å…¥é¢„æµ‹æ¨¡å‹å¹¶å¯è§†åŒ–æœªæ¥ 5 å¹´çš„å¢é•¿è¶‹åŠ¿"
    )
    
    print(f"æ‰§è¡Œç»“æœ: {result}")
    
    await chain.cleanup()

# è¿è¡Œç¤ºä¾‹
asyncio.run(advanced_langchain_demo())
```

## LangGraph å·¥ä½œæµé›†æˆ

### æ¦‚è¿°

LangGraph æ˜¯ LangChain çš„å·¥ä½œæµæ‰©å±•ï¼Œæ”¯æŒåˆ›å»ºå¤æ‚çš„æœ‰çŠ¶æ€ AI åº”ç”¨ã€‚E2B å¯ä»¥ä½œä¸º LangGraph ä¸­çš„èŠ‚ç‚¹ï¼Œå¤„ç†ä»£ç æ‰§è¡Œä»»åŠ¡ã€‚

### åŸºç¡€ LangGraph é›†æˆ

```python
from langgraph.graph import Graph, Node
from langgraph.prebuilt import ToolExecutor
from langchain.tools import Tool
from e2b_code_interpreter import Sandbox
from typing import TypedDict, Annotated, Sequence
import operator

class GraphState(TypedDict):
    """å›¾çŠ¶æ€å®šä¹‰"""
    messages: Annotated[Sequence[str], operator.add]
    code_history: Annotated[Sequence[str], operator.add]
    results: Annotated[Sequence[dict], operator.add]
    current_context: dict
    sandbox: Sandbox

class E2BLangGraphIntegration:
    """E2B LangGraph å·¥ä½œæµé›†æˆ"""
    
    def __init__(self):
        self.graph = Graph()
        self._build_graph()
    
    def _build_graph(self):
        """æ„å»ºå·¥ä½œæµå›¾"""
        
        # å®šä¹‰èŠ‚ç‚¹
        @Node
        async def analyze_request(state: GraphState) -> GraphState:
            """åˆ†æç”¨æˆ·è¯·æ±‚"""
            last_message = state["messages"][-1]
            
            # ä½¿ç”¨ LLM åˆ†æè¯·æ±‚ç±»å‹
            analysis = {
                "type": "data_analysis",  # æˆ– visualization, ml_model, etc.
                "requirements": ["pandas", "matplotlib"],
                "complexity": "medium"
            }
            
            state["current_context"] = analysis
            return state
        
        @Node
        async def setup_environment(state: GraphState) -> GraphState:
            """è®¾ç½®æ‰§è¡Œç¯å¢ƒ"""
            if not state.get("sandbox"):
                state["sandbox"] = await Sandbox.create()
            
            # æ ¹æ®éœ€æ±‚å®‰è£…åº“
            requirements = state["current_context"].get("requirements", [])
            setup_code = f"""
import sys
import subprocess

# å®‰è£…æ‰€éœ€åº“
libs = {requirements}
for lib in libs:
    try:
        __import__(lib)
        print(f"{{lib}} å·²å®‰è£…")
    except ImportError:
        print(f"æ­£åœ¨å®‰è£… {{lib}}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", lib])

print("ç¯å¢ƒè®¾ç½®å®Œæˆï¼")
"""
            
            result = await state["sandbox"].run_code(setup_code)
            state["results"].append({"type": "setup", "output": result.logs.stdout})
            return state
        
        @Node
        async def generate_code(state: GraphState) -> GraphState:
            """ç”Ÿæˆä»£ç """
            # ä½¿ç”¨ LLM ç”Ÿæˆä»£ç 
            task_type = state["current_context"]["type"]
            
            if task_type == "data_analysis":
                code = """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ç”Ÿæˆç¤ºä¾‹æ•°æ®
np.random.seed(42)
data = pd.DataFrame({
    'date': pd.date_range('2023-01-01', periods=100),
    'value': np.cumsum(np.random.randn(100)) + 100,
    'category': np.random.choice(['A', 'B', 'C'], 100)
})

# åŸºæœ¬ç»Ÿè®¡
print("æ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
print(data.describe())

# æŒ‰ç±»åˆ«åˆ†ç»„åˆ†æ
grouped = data.groupby('category')['value'].agg(['mean', 'std', 'count'])
print("\\næŒ‰ç±»åˆ«åˆ†ç»„:")
print(grouped)

# åˆ›å»ºå¯è§†åŒ–
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

# æ—¶é—´åºåˆ—å›¾
data.set_index('date')['value'].plot(ax=ax1, title='Value Over Time')
ax1.set_xlabel('Date')
ax1.set_ylabel('Value')

# ç±»åˆ«åˆ†å¸ƒ
data['category'].value_counts().plot(kind='bar', ax=ax2, title='Category Distribution')
ax2.set_xlabel('Category')
ax2.set_ylabel('Count')

plt.tight_layout()
plt.savefig('/tmp/analysis_results.png', dpi=300, bbox_inches='tight')
print("\\nåˆ†æå®Œæˆï¼å›¾è¡¨å·²ä¿å­˜ã€‚")
"""
            
            state["code_history"].append(code)
            return state
        
        @Node
        async def execute_code(state: GraphState) -> GraphState:
            """æ‰§è¡Œä»£ç """
            code = state["code_history"][-1]
            result = await state["sandbox"].run_code(code)
            
            execution_result = {
                "type": "execution",
                "stdout": result.logs.stdout,
                "stderr": result.logs.stderr,
                "error": result.error,
                "artifacts": []
            }
            
            # å¤„ç†ç”Ÿæˆçš„æ–‡ä»¶
            if result.artifacts:
                for artifact in result.artifacts:
                    if artifact.type == "image":
                        # ä¸‹è½½å›¾ç‰‡
                        content = await state["sandbox"].download_file(artifact.path)
                        execution_result["artifacts"].append({
                            "name": artifact.name,
                            "type": "image",
                            "size": len(content)
                        })
            
            state["results"].append(execution_result)
            return state
        
        @Node
        async def review_results(state: GraphState) -> GraphState:
            """å®¡æŸ¥å’Œä¼˜åŒ–ç»“æœ"""
            last_result = state["results"][-1]
            
            if last_result.get("error"):
                # å¦‚æœæœ‰é”™è¯¯ï¼Œç”Ÿæˆä¿®å¤ä»£ç 
                fix_code = f"""
# é”™è¯¯ä¿®å¤å°è¯•
try:
    {state["code_history"][-1]}
except Exception as e:
    print(f"é”™è¯¯: {{e}}")
    print("å°è¯•æ›¿ä»£æ–¹æ¡ˆ...")
    # è¿™é‡Œæ·»åŠ æ›¿ä»£é€»è¾‘
"""
                state["code_history"].append(fix_code)
                # è¿”å›æ‰§è¡ŒèŠ‚ç‚¹é‡è¯•
                return state
            
            # ç”Ÿæˆæ€»ç»“
            summary_code = """
print("\\n=== æ‰§è¡Œæ€»ç»“ ===")
print(f"æˆåŠŸæ‰§è¡Œäº† {len(state['code_history'])} æ®µä»£ç ")
print(f"ç”Ÿæˆäº† {len(state['results'][-1].get('artifacts', []))} ä¸ªæ–‡ä»¶")
print("ä»»åŠ¡å®Œæˆï¼")
"""
            
            result = await state["sandbox"].run_code(summary_code)
            state["results"].append({"type": "summary", "output": result.logs.stdout})
            
            return state
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        self.graph.add_node("analyze", analyze_request)
        self.graph.add_node("setup", setup_environment)
        self.graph.add_node("generate", generate_code)
        self.graph.add_node("execute", execute_code)
        self.graph.add_node("review", review_results)
        
        # å®šä¹‰è¾¹ï¼ˆå·¥ä½œæµï¼‰
        self.graph.add_edge("analyze", "setup")
        self.graph.add_edge("setup", "generate")
        self.graph.add_edge("generate", "execute")
        self.graph.add_edge("execute", "review")
        
        # æ¡ä»¶è¾¹ - å¦‚æœæœ‰é”™è¯¯åˆ™é‡è¯•
        def should_retry(state: GraphState) -> str:
            last_result = state["results"][-1]
            if last_result.get("error") and len(state["code_history"]) < 3:
                return "generate"
            return "END"
        
        self.graph.add_conditional_edges("review", should_retry)
        
        # è®¾ç½®å…¥å£ç‚¹
        self.graph.set_entry_point("analyze")
    
    async def run(self, message: str) -> GraphState:
        """è¿è¡Œå·¥ä½œæµ"""
        initial_state: GraphState = {
            "messages": [message],
            "code_history": [],
            "results": [],
            "current_context": {},
            "sandbox": None
        }
        
        # ç¼–è¯‘å¹¶è¿è¡Œå›¾
        app = self.graph.compile()
        final_state = await app.ainvoke(initial_state)
        
        # æ¸…ç†èµ„æº
        if final_state.get("sandbox"):
            await final_state["sandbox"].kill()
        
        return final_state

# ä½¿ç”¨ç¤ºä¾‹
async def langgraph_demo():
    workflow = E2BLangGraphIntegration()
    
    result = await workflow.run(
        "åˆ†æé”€å”®æ•°æ®ï¼Œåˆ›å»ºè¶‹åŠ¿å›¾è¡¨ï¼Œå¹¶ç”Ÿæˆæœˆåº¦æŠ¥å‘Š"
    )
    
    print("å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
    print(f"æ‰§è¡Œäº† {len(result['code_history'])} æ®µä»£ç ")
    print(f"ç”Ÿæˆäº† {len(result['results'])} ä¸ªç»“æœ")

# è¿è¡Œç¤ºä¾‹
asyncio.run(langgraph_demo())
```

### é«˜çº§ LangGraph å·¥ä½œæµ

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain.schema import BaseMessage, HumanMessage, AIMessage
import uuid

class AdvancedE2BWorkflow:
    """é«˜çº§ E2B LangGraph å·¥ä½œæµï¼Œæ”¯æŒå¤šä»£ç†åä½œ"""
    
    def __init__(self):
        self.memory = MemorySaver()
        self.workflow = self._create_workflow()
        
    def _create_workflow(self) -> StateGraph:
        """åˆ›å»ºå¤æ‚å·¥ä½œæµ"""
        
        workflow = StateGraph(GraphState)
        
        # æ•°æ®æ”¶é›†ä»£ç†
        async def data_collector_agent(state: GraphState) -> GraphState:
            """æ”¶é›†å’Œé¢„å¤„ç†æ•°æ®"""
            code = """
# æ•°æ®æ”¶é›†ä»£ç†
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# æ¨¡æ‹Ÿä»å¤šä¸ªæ•°æ®æºæ”¶é›†æ•°æ®
print("å¼€å§‹æ•°æ®æ”¶é›†...")

# æ•°æ®æº 1: é”€å”®æ•°æ®
sales_data = pd.DataFrame({
    'date': pd.date_range(start='2023-01-01', periods=365),
    'sales': np.random.exponential(1000, 365) * (1 + np.sin(np.arange(365) * 2 * np.pi / 365) * 0.3),
    'region': np.random.choice(['North', 'South', 'East', 'West'], 365)
})

# æ•°æ®æº 2: å®¢æˆ·æ•°æ®
customer_data = pd.DataFrame({
    'customer_id': range(1000),
    'join_date': pd.date_range(start='2020-01-01', periods=1000),
    'lifetime_value': np.random.lognormal(6, 1.5, 1000),
    'segment': np.random.choice(['Premium', 'Standard', 'Basic'], 1000, p=[0.2, 0.5, 0.3])
})

# æ•°æ®æº 3: äº§å“æ•°æ®
product_data = pd.DataFrame({
    'product_id': range(50),
    'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books'], 50),
    'price': np.random.uniform(10, 1000, 50),
    'stock': np.random.randint(0, 1000, 50)
})

# ä¿å­˜æ•°æ®
sales_data.to_csv('/tmp/sales_data.csv', index=False)
customer_data.to_csv('/tmp/customer_data.csv', index=False)
product_data.to_csv('/tmp/product_data.csv', index=False)

print(f"æ”¶é›†äº† {len(sales_data)} æ¡é”€å”®è®°å½•")
print(f"æ”¶é›†äº† {len(customer_data)} ä¸ªå®¢æˆ·ä¿¡æ¯")
print(f"æ”¶é›†äº† {len(product_data)} ä¸ªäº§å“ä¿¡æ¯")

# æ•°æ®è´¨é‡æ£€æŸ¥
print("\\næ•°æ®è´¨é‡æŠ¥å‘Š:")
print(f"é”€å”®æ•°æ®ç¼ºå¤±å€¼: {sales_data.isnull().sum().sum()}")
print(f"å®¢æˆ·æ•°æ®ç¼ºå¤±å€¼: {customer_data.isnull().sum().sum()}")
print(f"äº§å“æ•°æ®ç¼ºå¤±å€¼: {product_data.isnull().sum().sum()}")
"""
            
            if not state.get("sandbox"):
                state["sandbox"] = await Sandbox.create()
                
            result = await state["sandbox"].run_code(code)
            state["results"].append({
                "agent": "data_collector",
                "output": result.logs.stdout,
                "timestamp": datetime.now().isoformat()
            })
            
            return state
        
        # åˆ†æä»£ç†
        async def analyst_agent(state: GraphState) -> GraphState:
            """æ‰§è¡Œæ•°æ®åˆ†æ"""
            code = """
# æ•°æ®åˆ†æä»£ç†
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

print("å¼€å§‹æ•°æ®åˆ†æ...")

# åŠ è½½æ•°æ®
sales_data = pd.read_csv('/tmp/sales_data.csv')
customer_data = pd.read_csv('/tmp/customer_data.csv')
product_data = pd.read_csv('/tmp/product_data.csv')

# è½¬æ¢æ—¥æœŸåˆ—
sales_data['date'] = pd.to_datetime(sales_data['date'])
customer_data['join_date'] = pd.to_datetime(customer_data['join_date'])

# 1. é”€å”®è¶‹åŠ¿åˆ†æ
sales_monthly = sales_data.groupby(pd.Grouper(key='date', freq='M'))['sales'].agg(['sum', 'mean', 'std'])
print("\\næœˆåº¦é”€å”®ç»Ÿè®¡:")
print(sales_monthly.tail())

# 2. åŒºåŸŸæ€§èƒ½åˆ†æ
region_performance = sales_data.groupby('region')['sales'].agg(['sum', 'mean', 'count'])
region_performance['conversion_rate'] = region_performance['sum'] / region_performance['count']
print("\\nåŒºåŸŸæ€§èƒ½:")
print(region_performance)

# 3. å®¢æˆ·ç»†åˆ†åˆ†æ
customer_segments = customer_data.groupby('segment')['lifetime_value'].agg(['mean', 'median', 'std', 'count'])
print("\\nå®¢æˆ·ç»†åˆ†:")
print(customer_segments)

# 4. äº§å“åˆ†æ
product_analysis = product_data.groupby('category').agg({
    'price': ['mean', 'min', 'max'],
    'stock': ['sum', 'mean']
})
print("\\näº§å“ç±»åˆ«åˆ†æ:")
print(product_analysis)

# 5. ç›¸å…³æ€§åˆ†æ
# åˆ›å»ºç»¼åˆæ•°æ®é›†è¿›è¡Œç›¸å…³æ€§åˆ†æ
sales_daily = sales_data.groupby('date')['sales'].sum().reset_index()
sales_daily['day_of_week'] = pd.to_datetime(sales_daily['date']).dt.dayofweek
sales_daily['month'] = pd.to_datetime(sales_daily['date']).dt.month

correlation_matrix = sales_daily[['sales', 'day_of_week', 'month']].corr()
print("\\nç›¸å…³æ€§çŸ©é˜µ:")
print(correlation_matrix)

# åˆ›å»ºåˆ†ææŠ¥å‘Š
analysis_report = {
    'total_revenue': sales_data['sales'].sum(),
    'avg_daily_sales': sales_data['sales'].mean(),
    'best_region': region_performance['sum'].idxmax(),
    'best_segment': customer_segments['mean'].idxmax(),
    'total_customers': len(customer_data),
    'product_categories': len(product_data['category'].unique())
}

# ä¿å­˜åˆ†æç»“æœ
import json
with open('/tmp/analysis_report.json', 'w') as f:
    json.dump(analysis_report, f, indent=2)

print("\\nåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆï¼")
print(f"æ€»æ”¶å…¥: ${analysis_report['total_revenue']:,.2f}")
print(f"æœ€ä½³åŒºåŸŸ: {analysis_report['best_region']}")
print(f"æœ€ä½³å®¢æˆ·ç¾¤: {analysis_report['best_segment']}")
"""
            
            result = await state["sandbox"].run_code(code)
            state["results"].append({
                "agent": "analyst",
                "output": result.logs.stdout,
                "timestamp": datetime.now().isoformat()
            })
            
            return state
        
        # å¯è§†åŒ–ä»£ç†
        async def visualization_agent(state: GraphState) -> GraphState:
            """åˆ›å»ºæ•°æ®å¯è§†åŒ–"""
            code = """
# å¯è§†åŒ–ä»£ç†
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
from matplotlib.gridspec import GridSpec

print("åˆ›å»ºå¯è§†åŒ–...")

# åŠ è½½æ•°æ®
sales_data = pd.read_csv('/tmp/sales_data.csv')
customer_data = pd.read_csv('/tmp/customer_data.csv')
product_data = pd.read_csv('/tmp/product_data.csv')

with open('/tmp/analysis_report.json', 'r') as f:
    report = json.load(f)

# è®¾ç½®æ ·å¼
plt.style.use('seaborn-v0_8-darkgrid')
colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']

# åˆ›å»ºç»¼åˆä»ªè¡¨æ¿
fig = plt.figure(figsize=(20, 12))
gs = GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)

# 1. é”€å”®è¶‹åŠ¿å›¾
ax1 = fig.add_subplot(gs[0, :2])
sales_data['date'] = pd.to_datetime(sales_data['date'])
sales_monthly = sales_data.groupby(pd.Grouper(key='date', freq='M'))['sales'].sum()
ax1.plot(sales_monthly.index, sales_monthly.values, linewidth=2, color=colors[0])
ax1.fill_between(sales_monthly.index, sales_monthly.values, alpha=0.3, color=colors[0])
ax1.set_title('æœˆåº¦é”€å”®è¶‹åŠ¿', fontsize=16, fontweight='bold')
ax1.set_xlabel('æ—¥æœŸ')
ax1.set_ylabel('é”€å”®é¢ ($)')
ax1.tick_params(axis='x', rotation=45)

# 2. åŒºåŸŸé”€å”®åˆ†å¸ƒ
ax2 = fig.add_subplot(gs[0, 2])
region_sales = sales_data.groupby('region')['sales'].sum()
ax2.pie(region_sales.values, labels=region_sales.index, autopct='%1.1f%%', 
        colors=colors[:len(region_sales)], startangle=90)
ax2.set_title('åŒºåŸŸé”€å”®åˆ†å¸ƒ', fontsize=16, fontweight='bold')

# 3. å®¢æˆ·ç»†åˆ†åˆ†æ
ax3 = fig.add_subplot(gs[1, 0])
segment_data = customer_data.groupby('segment')['lifetime_value'].mean().sort_values()
bars = ax3.barh(segment_data.index, segment_data.values, color=colors[1])
ax3.set_xlabel('å¹³å‡ç”Ÿå‘½å‘¨æœŸä»·å€¼ ($)')
ax3.set_title('å®¢æˆ·ç»†åˆ†ä»·å€¼', fontsize=16, fontweight='bold')
for bar in bars:
    width = bar.get_width()
    ax3.text(width, bar.get_y() + bar.get_height()/2, 
             f'${width:,.0f}', ha='left', va='center')

# 4. äº§å“ç±»åˆ«åº“å­˜
ax4 = fig.add_subplot(gs[1, 1])
category_stock = product_data.groupby('category')['stock'].sum()
ax4.bar(category_stock.index, category_stock.values, color=colors[2])
ax4.set_xlabel('äº§å“ç±»åˆ«')
ax4.set_ylabel('æ€»åº“å­˜')
ax4.set_title('äº§å“åº“å­˜åˆ†å¸ƒ', fontsize=16, fontweight='bold')
ax4.tick_params(axis='x', rotation=45)

# 5. é”€å”®çƒ­åŠ›å›¾
ax5 = fig.add_subplot(gs[1, 2])
sales_data['month'] = pd.to_datetime(sales_data['date']).dt.month
sales_data['day'] = pd.to_datetime(sales_data['date']).dt.day
sales_pivot = sales_data.pivot_table(values='sales', index='day', columns='month', aggfunc='mean')
sns.heatmap(sales_pivot, cmap='YlOrRd', ax=ax5, cbar_kws={'label': 'å¹³å‡é”€å”®é¢'})
ax5.set_title('é”€å”®çƒ­åŠ›å›¾ (æ—¥/æœˆ)', fontsize=16, fontweight='bold')

# 6. å…³é”®æŒ‡æ ‡å¡ç‰‡
ax6 = fig.add_subplot(gs[2, :])
ax6.axis('off')

# åˆ›å»ºæŒ‡æ ‡æ–‡æœ¬
metrics_text = f"""
ğŸ“Š å…³é”®ä¸šåŠ¡æŒ‡æ ‡

ğŸ’° æ€»æ”¶å…¥: ${report['total_revenue']:,.2f}
ğŸ“ˆ æ—¥å‡é”€å”®: ${report['avg_daily_sales']:,.2f}
ğŸ† æœ€ä½³åŒºåŸŸ: {report['best_region']}
ğŸ‘¥ æ€»å®¢æˆ·æ•°: {report['total_customers']:,}
ğŸ¯ æœ€ä½³å®¢æˆ·ç¾¤: {report['best_segment']}
ğŸ“¦ äº§å“ç±»åˆ«: {report['product_categories']}
"""

ax6.text(0.5, 0.5, metrics_text, fontsize=18, ha='center', va='center',
         bbox=dict(boxstyle='round,pad=1', facecolor='lightgray', alpha=0.8))

plt.suptitle('ä¸šåŠ¡åˆ†æä»ªè¡¨æ¿', fontsize=24, fontweight='bold', y=0.98)
plt.savefig('/tmp/business_dashboard.png', dpi=300, bbox_inches='tight')
print("ä»ªè¡¨æ¿å·²åˆ›å»ºï¼")

# åˆ›å»ºå•ç‹¬çš„è¶‹åŠ¿é¢„æµ‹å›¾
fig2, ax = plt.subplots(figsize=(12, 6))
from sklearn.linear_model import LinearRegression

# å‡†å¤‡æ•°æ®
sales_data['date_numeric'] = (sales_data['date'] - sales_data['date'].min()).dt.days
X = sales_data[['date_numeric']]
y = sales_data['sales']

# è®­ç»ƒæ¨¡å‹
model = LinearRegression()
model.fit(X, y)

# é¢„æµ‹æœªæ¥ 30 å¤©
future_days = pd.DataFrame({
    'date_numeric': range(sales_data['date_numeric'].max() + 1, 
                          sales_data['date_numeric'].max() + 31)
})
predictions = model.predict(future_days)

# ç»˜å›¾
ax.scatter(sales_data['date'], sales_data['sales'], alpha=0.5, label='å†å²æ•°æ®')
ax.plot(sales_data['date'], model.predict(X), color='red', linewidth=2, label='è¶‹åŠ¿çº¿')

future_dates = pd.date_range(sales_data['date'].max() + timedelta(days=1), periods=30)
ax.plot(future_dates, predictions, color='green', linewidth=2, linestyle='--', label='é¢„æµ‹')
ax.fill_between(future_dates, predictions * 0.9, predictions * 1.1, alpha=0.3, color='green')

ax.set_title('é”€å”®è¶‹åŠ¿ä¸é¢„æµ‹', fontsize=16, fontweight='bold')
ax.set_xlabel('æ—¥æœŸ')
ax.set_ylabel('é”€å”®é¢ ($)')
ax.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('/tmp/sales_forecast.png', dpi=300)

print("é¢„æµ‹å›¾è¡¨å·²åˆ›å»ºï¼")
print(f"é¢„æµ‹ä¸‹æœˆé”€å”®é¢: ${predictions.sum():,.2f}")
"""
            
            result = await state["sandbox"].run_code(code)
            state["results"].append({
                "agent": "visualization",
                "output": result.logs.stdout,
                "timestamp": datetime.now().isoformat()
            })
            
            return state
        
        # æŠ¥å‘Šç”Ÿæˆä»£ç†
        async def report_agent(state: GraphState) -> GraphState:
            """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
            code = """
# æŠ¥å‘Šç”Ÿæˆä»£ç†
import json
from datetime import datetime
import pandas as pd

print("ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")

# åŠ è½½åˆ†æç»“æœ
with open('/tmp/analysis_report.json', 'r') as f:
    analysis = json.load(f)

# åˆ›å»º Markdown æŠ¥å‘Š
report = f\"\"\"
# ä¸šåŠ¡åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘ŠåŸºäºæœ€æ–°çš„é”€å”®ã€å®¢æˆ·å’Œäº§å“æ•°æ®ï¼Œæä¾›å…¨é¢çš„ä¸šåŠ¡æ´å¯Ÿå’Œå»ºè®®ã€‚

### å…³é”®å‘ç°

1. **æ€»æ”¶å…¥**: ${analysis['total_revenue']:,.2f}
2. **æ—¥å‡é”€å”®é¢**: ${analysis['avg_daily_sales']:,.2f}
3. **è¡¨ç°æœ€ä½³åŒºåŸŸ**: {analysis['best_region']}
4. **æœ€æœ‰ä»·å€¼å®¢æˆ·ç¾¤**: {analysis['best_segment']}
5. **æ´»è·ƒå®¢æˆ·æ€»æ•°**: {analysis['total_customers']:,}

## è¯¦ç»†åˆ†æ

### é”€å”®è¡¨ç°
- é”€å”®æ•°æ®æ˜¾ç¤ºç¨³å®šå¢é•¿è¶‹åŠ¿
- å­£èŠ‚æ€§æ³¢åŠ¨æ˜æ˜¾ï¼Œéœ€è¦é’ˆå¯¹æ€§è¥é”€ç­–ç•¥
- åŒºåŸŸå·®å¼‚æ˜¾è‘—ï¼Œå»ºè®®åŠ å¼ºå¼±åŠ¿åŒºåŸŸæ¨å¹¿

### å®¢æˆ·æ´å¯Ÿ
- Premium å®¢æˆ·ç¾¤ä½“è™½ç„¶æ•°é‡å°‘ä½†ä»·å€¼é«˜
- éœ€è¦åˆ¶å®šå®¢æˆ·ä¿ç•™ç­–ç•¥ä»¥æé«˜ç”Ÿå‘½å‘¨æœŸä»·å€¼
- è€ƒè™‘æ¨å‡ºå¿ è¯šåº¦è®¡åˆ’

### äº§å“ç­–ç•¥
- åº“å­˜åˆ†å¸ƒä¸å‡ï¼Œéœ€è¦ä¼˜åŒ–ä¾›åº”é“¾
- æŸäº›ç±»åˆ«äº§å“éœ€æ±‚æ—ºç››ï¼Œå»ºè®®å¢åŠ åº“å­˜
- ä»·æ ¼ç­–ç•¥å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–

## å»ºè®®è¡ŒåŠ¨

1. **çŸ­æœŸï¼ˆ1-3ä¸ªæœˆï¼‰**
   - åœ¨è¡¨ç°æœ€ä½³çš„åŒºåŸŸå¢åŠ è¥é”€æŠ•å…¥
   - ä¸º Premium å®¢æˆ·æ¨å‡ºä¸“å±æœåŠ¡
   - ä¼˜åŒ–åº“å­˜ç®¡ç†ç³»ç»Ÿ

2. **ä¸­æœŸï¼ˆ3-6ä¸ªæœˆï¼‰**
   - å¼€å‘æ–°çš„å®¢æˆ·ç»†åˆ†ç­–ç•¥
   - å®æ–½åŠ¨æ€å®šä»·ç³»ç»Ÿ
   - æ‰©å±•åˆ°æ–°çš„åœ°ç†åŒºåŸŸ

3. **é•¿æœŸï¼ˆ6-12ä¸ªæœˆï¼‰**
   - å»ºç«‹é¢„æµ‹åˆ†æç³»ç»Ÿ
   - å¼€å‘å®¢æˆ·ç»ˆèº«ä»·å€¼æ¨¡å‹
   - å®æ–½å…¨æ¸ é“è¥é”€ç­–ç•¥

## é™„ä»¶
- [ä¸šåŠ¡ä»ªè¡¨æ¿](/tmp/business_dashboard.png)
- [é”€å”®é¢„æµ‹å›¾è¡¨](/tmp/sales_forecast.png)
- [åŸå§‹æ•°æ®æ–‡ä»¶](/tmp/)

---
*æœ¬æŠ¥å‘Šç”± E2B AI åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
\"\"\"

# ä¿å­˜æŠ¥å‘Š
with open('/tmp/final_report.md', 'w', encoding='utf-8') as f:
    f.write(report)

print("æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
print(f"æŠ¥å‘Šå·²ä¿å­˜è‡³: /tmp/final_report.md")

# ç”Ÿæˆæ‰§è¡Œæ€»ç»“
summary = {
    "workflow_complete": True,
    "agents_executed": 4,
    "files_generated": [
        "sales_data.csv",
        "customer_data.csv", 
        "product_data.csv",
        "analysis_report.json",
        "business_dashboard.png",
        "sales_forecast.png",
        "final_report.md"
    ],
    "execution_time": "çº¦ 2 åˆ†é’Ÿ",
    "status": "SUCCESS"
}

with open('/tmp/workflow_summary.json', 'w') as f:
    json.dump(summary, f, indent=2)

print("\\nå·¥ä½œæµæ‰§è¡Œæ€»ç»“:")
print(json.dumps(summary, indent=2))
"""
            
            result = await state["sandbox"].run_code(code)
            state["results"].append({
                "agent": "report_generator",
                "output": result.logs.stdout,
                "timestamp": datetime.now().isoformat()
            })
            
            # ä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶
            files_to_download = [
                '/tmp/business_dashboard.png',
                '/tmp/sales_forecast.png',
                '/tmp/final_report.md'
            ]
            
            for file_path in files_to_download:
                try:
                    content = await state["sandbox"].download_file(file_path)
                    # ä¿å­˜åˆ°æœ¬åœ°
                    local_path = file_path.split('/')[-1]
                    with open(local_path, 'wb') as f:
                        f.write(content if isinstance(content, bytes) else content.encode())
                    print(f"å·²ä¸‹è½½: {local_path}")
                except Exception as e:
                    print(f"ä¸‹è½½å¤±è´¥ {file_path}: {e}")
            
            return state
        
        # æ„å»ºå·¥ä½œæµ
        workflow.add_node("collect_data", data_collector_agent)
        workflow.add_node("analyze", analyst_agent)
        workflow.add_node("visualize", visualization_agent)
        workflow.add_node("report", report_agent)
        
        # å®šä¹‰å·¥ä½œæµ
        workflow.add_edge("collect_data", "analyze")
        workflow.add_edge("analyze", "visualize")
        workflow.add_edge("visualize", "report")
        workflow.add_edge("report", END)
        
        workflow.set_entry_point("collect_data")
        
        return workflow
    
    async def execute(self, task: str, thread_id: str = None) -> dict:
        """æ‰§è¡Œå·¥ä½œæµ"""
        if not thread_id:
            thread_id = str(uuid.uuid4())
        
        initial_state = GraphState(
            messages=[task],
            code_history=[],
            results=[],
            current_context={"task": task},
            sandbox=None
        )
        
        # ç¼–è¯‘å·¥ä½œæµ
        app = self.workflow.compile(checkpointer=self.memory)
        
        # æ‰§è¡Œå·¥ä½œæµ
        config = {"configurable": {"thread_id": thread_id}}
        
        try:
            final_state = await app.ainvoke(initial_state, config)
            
            # æ¸…ç†èµ„æº
            if final_state.get("sandbox"):
                await final_state["sandbox"].kill()
            
            return {
                "success": True,
                "thread_id": thread_id,
                "results": final_state["results"],
                "files_generated": len([r for r in final_state["results"] if "agent" in r])
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "thread_id": thread_id
            }

# ä½¿ç”¨ç¤ºä¾‹
async def advanced_langgraph_demo():
    workflow = AdvancedE2BWorkflow()
    
    result = await workflow.execute(
        "æ‰§è¡Œå®Œæ•´çš„ä¸šåŠ¡åˆ†ææµç¨‹ï¼šæ”¶é›†æ•°æ®ã€åˆ†æè¶‹åŠ¿ã€åˆ›å»ºå¯è§†åŒ–ã€ç”ŸæˆæŠ¥å‘Š"
    )
    
    if result["success"]:
        print(f"å·¥ä½œæµæˆåŠŸå®Œæˆï¼")
        print(f"çº¿ç¨‹ ID: {result['thread_id']}")
        print(f"æ‰§è¡Œäº† {result['files_generated']} ä¸ªä»£ç†")
    else:
        print(f"å·¥ä½œæµå¤±è´¥: {result['error']}")

# è¿è¡Œç¤ºä¾‹
asyncio.run(advanced_langgraph_demo())
```

## Autogen å¤šä»£ç†é›†æˆ

### æ¦‚è¿°

Autogen æ˜¯å¾®è½¯å¼€å‘çš„å¤šä»£ç†æ¡†æ¶ï¼ŒE2B å¯ä»¥ä¸º Autogen ä»£ç†æä¾›å®‰å…¨çš„ä»£ç æ‰§è¡Œç¯å¢ƒã€‚

### åŸºç¡€ Autogen é›†æˆ

```python
import autogen
from e2b_code_interpreter import Sandbox
from typing import Dict, Any, List
import asyncio

class E2BCodeExecutor:
    """E2B ä»£ç æ‰§è¡Œå™¨ for Autogen"""
    
    def __init__(self):
        self.sandbox = Sandbox()
        
    def execute_code(self, code: str) -> Dict[str, Any]:
        """æ‰§è¡Œä»£ç å¹¶è¿”å›ç»“æœ"""
        result = self.sandbox.run_code(code)
        return {
            "exit_code": 0 if not result.error else 1,
            "output": result.logs.stdout,
            "error": result.logs.stderr or result.error
        }
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.sandbox.kill()

# é…ç½® Autogen
config_list = [{
    "model": "gpt-4",
    "api_key": "your_openai_api_key"
}]

# åˆ›å»º E2B æ‰§è¡Œå™¨
executor = E2BCodeExecutor()

# åˆ›å»ºåŠ©æ‰‹ä»£ç†
assistant = autogen.AssistantAgent(
    name="coding_assistant",
    llm_config={
        "config_list": config_list,
        "temperature": 0,
        "functions": [
            {
                "name": "execute_python_code",
                "description": "Execute Python code in a secure sandbox",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "code": {
                            "type": "string",
                            "description": "Python code to execute"
                        }
                    },
                    "required": ["code"]
                }
            }
        ]
    },
    system_message="""You are a helpful AI assistant that can write and execute Python code.
    When asked to perform tasks, write Python code and use the execute_python_code function to run it.
    Always include proper error handling and comments in your code."""
)

# åˆ›å»ºç”¨æˆ·ä»£ç†
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    code_execution_config=False,  # ç¦ç”¨æœ¬åœ°æ‰§è¡Œ
    function_map={
        "execute_python_code": executor.execute_code
    }
)

# ä½¿ç”¨ç¤ºä¾‹
user_proxy.initiate_chat(
    assistant,
    message="""
    åˆ›å»ºä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹æ¥é¢„æµ‹æˆ¿ä»·ï¼š
    1. ç”Ÿæˆåˆæˆæ•°æ®é›†ï¼ˆ1000ä¸ªæ ·æœ¬ï¼‰
    2. è¿›è¡Œç‰¹å¾å·¥ç¨‹
    3. è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶æ¯”è¾ƒ
    4. åˆ›å»ºæ€§èƒ½å¯è§†åŒ–
    """
)

# æ¸…ç†
executor.cleanup()
```

### é«˜çº§ Autogen å¤šä»£ç†ç³»ç»Ÿ

```python
import autogen
from autogen.agentchat.contrib.capabilities.teachability import Teachability
from e2b_code_interpreter import Sandbox
import json
from typing import Optional

class E2BMultiAgentSystem:
    """E2B æ”¯æŒçš„ Autogen å¤šä»£ç†ç³»ç»Ÿ"""
    
    def __init__(self):
        self.sandboxes = {}  # æ¯ä¸ªä»£ç†ä¸€ä¸ªæ²™ç®±
        self.shared_data = {}  # ä»£ç†é—´å…±äº«æ•°æ®
        self._setup_agents()
    
    def _create_sandbox_for_agent(self, agent_name: str) -> Sandbox:
        """ä¸ºä»£ç†åˆ›å»ºç‹¬ç«‹æ²™ç®±"""
        sandbox = Sandbox()
        self.sandboxes[agent_name] = sandbox
        return sandbox
    
    def _setup_agents(self):
        """è®¾ç½®å¤šä»£ç†ç³»ç»Ÿ"""
        
        # LLM é…ç½®
        llm_config = {
            "config_list": [{
                "model": "gpt-4",
                "api_key": "your_api_key"
            }],
            "temperature": 0
        }
        
        # 1. æ•°æ®å·¥ç¨‹å¸ˆä»£ç†
        self.data_engineer = autogen.AssistantAgent(
            name="data_engineer",
            llm_config=llm_config,
            system_message="""You are a data engineer specialized in:
            - Data collection and cleaning
            - ETL pipelines
            - Database operations
            - Data validation
            
            Always use the sandbox to execute code."""
        )
        
        # 2. æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆä»£ç†
        self.ml_engineer = autogen.AssistantAgent(
            name="ml_engineer",
            llm_config=llm_config,
            system_message="""You are a machine learning engineer specialized in:
            - Model development and training
            - Feature engineering
            - Model evaluation and optimization
            - Deployment strategies
            
            Always use the sandbox to execute code."""
        )
        
        # 3. æ•°æ®ç§‘å­¦å®¶ä»£ç†
        self.data_scientist = autogen.AssistantAgent(
            name="data_scientist",
            llm_config=llm_config,
            system_message="""You are a data scientist specialized in:
            - Statistical analysis
            - Data visualization
            - Insights generation
            - A/B testing
            
            Always use the sandbox to execute code."""
        )
        
        # 4. é¡¹ç›®ç»ç†ä»£ç†
        self.project_manager = autogen.AssistantAgent(
            name="project_manager",
            llm_config=llm_config,
            system_message="""You are a project manager who:
            - Coordinates between team members
            - Tracks progress
            - Ensures deliverables meet requirements
            - Manages timelines
            
            You don't write code but guide the team."""
        )
        
        # åˆ›å»ºç”¨æˆ·ä»£ç†
        self.user_proxy = autogen.UserProxyAgent(
            name="user_proxy",
            human_input_mode="NEVER",
            max_consecutive_auto_reply=20,
            code_execution_config=False,
            function_map=self._create_function_map()
        )
        
        # æ·»åŠ å¯å­¦ä¹ èƒ½åŠ›
        teachability = Teachability(
            verbosity=0,
            reset_db=False,
            path_to_db_dir="./tmp/autogen_teachability_db"
        )
        teachability.add_to_agent(self.data_scientist)
        
    def _create_function_map(self) -> dict:
        """åˆ›å»ºå‡½æ•°æ˜ å°„"""
        
        def execute_in_sandbox(agent_name: str, code: str) -> dict:
            """åœ¨ç‰¹å®šä»£ç†çš„æ²™ç®±ä¸­æ‰§è¡Œä»£ç """
            if agent_name not in self.sandboxes:
                self._create_sandbox_for_agent(agent_name)
            
            sandbox = self.sandboxes[agent_name]
            result = sandbox.run_code(code)
            
            return {
                "success": not bool(result.error),
                "output": result.logs.stdout,
                "error": result.error,
                "artifacts": [a.name for a in result.artifacts] if result.artifacts else []
            }
        
        def share_data(key: str, value: Any, from_agent: str) -> dict:
            """åœ¨ä»£ç†é—´å…±äº«æ•°æ®"""
            self.shared_data[key] = {
                "value": value,
                "from": from_agent,
                "timestamp": datetime.now().isoformat()
            }
            return {"success": True, "message": f"Data '{key}' shared successfully"}
        
        def get_shared_data(key: str) -> dict:
            """è·å–å…±äº«æ•°æ®"""
            if key in self.shared_data:
                return {
                    "success": True,
                    "data": self.shared_data[key]
                }
            return {"success": False, "message": f"No data found for key '{key}'"}
        
        return {
            "execute_in_sandbox": execute_in_sandbox,
            "share_data": share_data,
            "get_shared_data": get_shared_data
        }
    
    async def run_project(self, project_description: str):
        """è¿è¡Œå®Œæ•´é¡¹ç›®"""
        
        # åˆ›å»ºç¾¤èŠ
        groupchat = autogen.GroupChat(
            agents=[
                self.user_proxy,
                self.project_manager,
                self.data_engineer,
                self.ml_engineer,
                self.data_scientist
            ],
            messages=[],
            max_round=30
        )
        
        # åˆ›å»ºç¾¤èŠç®¡ç†å™¨
        manager = autogen.GroupChatManager(
            groupchat=groupchat,
            llm_config={
                "config_list": [{
                    "model": "gpt-4",
                    "api_key": "your_api_key"
                }]
            }
        )
        
        # å¯åŠ¨é¡¹ç›®
        await self.user_proxy.a_initiate_chat(
            manager,
            message=f"""
            Project: {project_description}
            
            Project Manager, please coordinate the team to complete this project.
            Break it down into tasks and assign to appropriate team members.
            """
        )
        
        # ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š
        self._generate_project_report()
        
    def _generate_project_report(self):
        """ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š"""
        report = {
            "project_summary": {
                "agents_involved": list(self.sandboxes.keys()),
                "data_shared": len(self.shared_data),
                "sandboxes_created": len(self.sandboxes)
            },
            "shared_data": self.shared_data,
            "execution_logs": []
        }
        
        # æ”¶é›†æ‰§è¡Œæ—¥å¿—
        for agent_name, sandbox in self.sandboxes.items():
            # è·å–æ²™ç®±ä¸­çš„æ–‡ä»¶åˆ—è¡¨
            files_code = """
import os
import json

files = []
for root, dirs, filenames in os.walk('/tmp'):
    for filename in filenames:
        files.append(os.path.join(root, filename))

print(json.dumps(files))
"""
            result = sandbox.run_code(files_code)
            if result.logs.stdout:
                try:
                    files = json.loads(result.logs.stdout)
                    report["execution_logs"].append({
                        "agent": agent_name,
                        "files_created": files
                    })
                except:
                    pass
        
        # ä¿å­˜æŠ¥å‘Š
        with open("project_report.json", "w") as f:
            json.dump(report, f, indent=2)
        
        print("é¡¹ç›®æŠ¥å‘Šå·²ç”Ÿæˆ: project_report.json")
    
    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        for sandbox in self.sandboxes.values():
            sandbox.kill()

# ä½¿ç”¨ç¤ºä¾‹
async def autogen_demo():
    system = E2BMultiAgentSystem()
    
    await system.run_project("""
    å¼€å‘ä¸€ä¸ªå®¢æˆ·æµå¤±é¢„æµ‹ç³»ç»Ÿï¼š
    1. ç”Ÿæˆæ¨¡æ‹Ÿçš„å®¢æˆ·æ•°æ®ï¼ˆåŒ…æ‹¬è¡Œä¸ºã€äº¤æ˜“ã€äººå£ç»Ÿè®¡ä¿¡æ¯ï¼‰
    2. è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æ
    3. æ„å»ºå¤šä¸ªé¢„æµ‹æ¨¡å‹
    4. è¯„ä¼°æ¨¡å‹æ€§èƒ½
    5. åˆ›å»ºå¯è§†åŒ–æŠ¥å‘Š
    6. æä¾›ä¸šåŠ¡å»ºè®®
    """)
    
    system.cleanup()

# è¿è¡Œç¤ºä¾‹
asyncio.run(autogen_demo())
```

## Vercel AI SDK é›†æˆ

### æ¦‚è¿°

Vercel AI SDK æä¾›äº†æ„å»º AI åº”ç”¨çš„å·¥å…·ï¼ŒE2B å¯ä»¥ä½œä¸ºåç«¯æ‰§è¡Œå¼•æ“ã€‚

### Next.js + AI SDK + E2B é›†æˆ

```typescript
// app/api/execute/route.ts
import { OpenAIStream, StreamingTextResponse } from 'ai'
import { Sandbox } from '@e2b/code-interpreter'
import OpenAI from 'openai'

const openai = new OpenAI()

export async function POST(req: Request) {
  const { messages, code } = await req.json()
  
  // åˆ›å»º E2B æ²™ç®±
  const sandbox = await Sandbox.create()
  
  try {
    // å¦‚æœæœ‰ä»£ç ï¼Œå…ˆæ‰§è¡Œ
    let codeResult = null
    if (code) {
      codeResult = await sandbox.runCode(code)
    }
    
    // å‡†å¤‡æ¶ˆæ¯ï¼ŒåŒ…å«ä»£ç æ‰§è¡Œç»“æœ
    const enhancedMessages = [...messages]
    if (codeResult) {
      enhancedMessages.push({
        role: 'system',
        content: `Code execution result:\nOutput: ${codeResult.logs.stdout}\nError: ${codeResult.error || 'None'}`
      })
    }
    
    // åˆ›å»º OpenAI æµ
    const response = await openai.chat.completions.create({
      model: 'gpt-4',
      messages: enhancedMessages,
      stream: true,
      functions: [{
        name: 'execute_code',
        description: 'Execute Python code in sandbox',
        parameters: {
          type: 'object',
          properties: {
            code: {
              type: 'string',
              description: 'Python code to execute'
            }
          },
          required: ['code']
        }
      }]
    })
    
    // å¤„ç†æµå¼å“åº”
    const stream = OpenAIStream(response, {
      async onCompletion(completion) {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œä»£ç 
        try {
          const parsed = JSON.parse(completion)
          if (parsed.function_call?.name === 'execute_code') {
            const code = JSON.parse(parsed.function_call.arguments).code
            const result = await sandbox.runCode(code)
            
            // å¯ä»¥å°†ç»“æœå­˜å‚¨æˆ–è¿”å›ç»™å®¢æˆ·ç«¯
            console.log('Code executed:', result)
          }
        } catch (e) {
          // ä¸æ˜¯å‡½æ•°è°ƒç”¨ï¼Œå¿½ç•¥
        }
      },
      async onFinal() {
        // æ¸…ç†æ²™ç®±
        await sandbox.kill()
      }
    })
    
    return new StreamingTextResponse(stream)
    
  } catch (error) {
    await sandbox.kill()
    throw error
  }
}
```

### React ç»„ä»¶é›†æˆ

```tsx
// components/CodeInterpreter.tsx
'use client'

import { useChat } from 'ai/react'
import { useState, useCallback } from 'react'
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter'
import { vscDarkPlus } from 'react-syntax-highlighter/dist/esm/styles/prism'

interface CodeExecution {
  code: string
  output: string
  error?: string
  timestamp: Date
}

export function CodeInterpreter() {
  const [executions, setExecutions] = useState<CodeExecution[]>([])
  const [isExecuting, setIsExecuting] = useState(false)
  
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: '/api/chat-with-code',
    onResponse: async (response) => {
      // å¤„ç†ä»£ç æ‰§è¡Œå“åº”
      const reader = response.body?.getReader()
      if (!reader) return
      
      while (true) {
        const { done, value } = await reader.read()
        if (done) break
        
        const text = new TextDecoder().decode(value)
        // è§£æå¹¶å¤„ç†ä»£ç æ‰§è¡Œäº‹ä»¶
        try {
          const data = JSON.parse(text)
          if (data.type === 'code_execution') {
            setExecutions(prev => [...prev, data.execution])
          }
        } catch (e) {
          // å¸¸è§„æ–‡æœ¬å“åº”
        }
      }
    }
  })
  
  const executeCode = useCallback(async (code: string) => {
    setIsExecuting(true)
    
    try {
      const response = await fetch('/api/execute', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ code })
      })
      
      const result = await response.json()
      
      setExecutions(prev => [...prev, {
        code,
        output: result.output,
        error: result.error,
        timestamp: new Date()
      }])
      
    } catch (error) {
      console.error('Execution error:', error)
    } finally {
      setIsExecuting(false)
    }
  }, [])
  
  return (
    <div className="flex h-screen">
      {/* èŠå¤©é¢æ¿ */}
      <div className="flex-1 flex flex-col">
        <div className="flex-1 overflow-y-auto p-4 space-y-4">
          {messages.map(message => (
            <div
              key={message.id}
              className={`flex ${
                message.role === 'user' ? 'justify-end' : 'justify-start'
              }`}
            >
              <div
                className={`max-w-md px-4 py-2 rounded-lg ${
                  message.role === 'user'
                    ? 'bg-blue-500 text-white'
                    : 'bg-gray-200 text-gray-800'
                }`}
              >
                {message.content}
              </div>
            </div>
          ))}
        </div>
        
        <form onSubmit={handleSubmit} className="p-4 border-t">
          <div className="flex space-x-2">
            <input
              value={input}
              onChange={handleInputChange}
              placeholder="Ask me to write and execute code..."
              className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
              disabled={isLoading}
            />
            <button
              type="submit"
              disabled={isLoading}
              className="px-6 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:opacity-50"
            >
              Send
            </button>
          </div>
        </form>
      </div>
      
      {/* ä»£ç æ‰§è¡Œé¢æ¿ */}
      <div className="w-1/2 border-l flex flex-col">
        <div className="p-4 border-b">
          <h2 className="text-lg font-semibold">Code Executions</h2>
        </div>
        
        <div className="flex-1 overflow-y-auto p-4 space-y-4">
          {executions.map((execution, idx) => (
            <div key={idx} className="border rounded-lg p-4 space-y-2">
              <div className="flex justify-between items-center">
                <span className="text-sm text-gray-500">
                  {execution.timestamp.toLocaleTimeString()}
                </span>
                <button
                  onClick={() => executeCode(execution.code)}
                  className="text-sm text-blue-500 hover:underline"
                >
                  Re-run
                </button>
              </div>
              
              <div className="space-y-2">
                <div className="text-sm font-medium">Code:</div>
                <SyntaxHighlighter
                  language="python"
                  style={vscDarkPlus}
                  className="text-sm"
                >
                  {execution.code}
                </SyntaxHighlighter>
              </div>
              
              {execution.output && (
                <div className="space-y-2">
                  <div className="text-sm font-medium">Output:</div>
                  <pre className="bg-gray-100 p-2 rounded text-sm overflow-x-auto">
                    {execution.output}
                  </pre>
                </div>
              )}
              
              {execution.error && (
                <div className="space-y-2">
                  <div className="text-sm font-medium text-red-500">Error:</div>
                  <pre className="bg-red-50 p-2 rounded text-sm text-red-700 overflow-x-auto">
                    {execution.error}
                  </pre>
                </div>
              )}
            </div>
          ))}
        </div>
      </div>
    </div>
  )
}
```

### æµå¼æ‰§è¡Œå’Œå®æ—¶åé¦ˆ

```typescript
// app/api/stream-execute/route.ts
import { Sandbox } from '@e2b/code-interpreter'

export async function POST(req: Request) {
  const { code, sessionId } = await req.json()
  
  const encoder = new TextEncoder()
  const stream = new TransformStream()
  const writer = stream.writable.getWriter()
  
  // å¼‚æ­¥æ‰§è¡Œ
  ;(async () => {
    const sandbox = await Sandbox.create()
    
    try {
      // å‘é€å¼€å§‹äº‹ä»¶
      await writer.write(
        encoder.encode(`data: ${JSON.stringify({
          type: 'start',
          sessionId
        })}\n\n`)
      )
      
      // åˆ†æ®µæ‰§è¡Œä»£ç 
      const codeBlocks = code.split('\n\n')
      
      for (let i = 0; i < codeBlocks.length; i++) {
        const block = codeBlocks[i]
        
        // å‘é€è¿›åº¦
        await writer.write(
          encoder.encode(`data: ${JSON.stringify({
            type: 'progress',
            current: i + 1,
            total: codeBlocks.length
          })}\n\n`)
        )
        
        // æ‰§è¡Œä»£ç å—
        const result = await sandbox.runCode(block)
        
        // å‘é€ç»“æœ
        await writer.write(
          encoder.encode(`data: ${JSON.stringify({
            type: 'result',
            blockIndex: i,
            output: result.logs.stdout,
            error: result.error
          })}\n\n`)
        )
        
        // å¦‚æœæœ‰æ–‡ä»¶ç”Ÿæˆï¼Œå‘é€æ–‡ä»¶ä¿¡æ¯
        if (result.artifacts) {
          for (const artifact of result.artifacts) {
            await writer.write(
              encoder.encode(`data: ${JSON.stringify({
                type: 'artifact',
                name: artifact.name,
                type: artifact.type,
                size: artifact.size
              })}\n\n`)
            )
          }
        }
      }
      
      // å‘é€å®Œæˆäº‹ä»¶
      await writer.write(
        encoder.encode(`data: ${JSON.stringify({
          type: 'complete'
        })}\n\n`)
      )
      
    } catch (error) {
      await writer.write(
        encoder.encode(`data: ${JSON.stringify({
          type: 'error',
          message: error.message
        })}\n\n`)
      )
    } finally {
      await sandbox.kill()
      await writer.close()
    }
  })()
  
  return new Response(stream.readable, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive'
    }
  })
}
```

## AgentKit ç¼–ç ä»£ç†

### æ¦‚è¿°

AgentKit æ˜¯ä¸€ä¸ªä¸“æ³¨äºç¼–ç ä»»åŠ¡çš„ä»£ç†æ¡†æ¶ï¼ŒE2B æä¾›äº†å®Œç¾çš„æ‰§è¡Œç¯å¢ƒã€‚

### åŸºç¡€ AgentKit é›†æˆ

```typescript
import { Agent, Task, Tool } from '@agentkit/core'
import { Sandbox } from '@e2b/code-interpreter'

// å®šä¹‰ E2B å·¥å…·
class E2BTool extends Tool {
  private sandbox: Sandbox | null = null
  
  async initialize() {
    this.sandbox = await Sandbox.create()
  }
  
  async execute(params: { code: string, language?: string }) {
    if (!this.sandbox) {
      throw new Error('Sandbox not initialized')
    }
    
    const result = await this.sandbox.runCode(params.code)
    
    return {
      success: !result.error,
      output: result.logs.stdout,
      error: result.error,
      artifacts: result.artifacts?.map(a => ({
        name: a.name,
        type: a.type
      }))
    }
  }
  
  async cleanup() {
    if (this.sandbox) {
      await this.sandbox.kill()
    }
  }
  
  getSchema() {
    return {
      name: 'execute_code',
      description: 'Execute code in a secure sandbox',
      parameters: {
        type: 'object',
        properties: {
          code: {
            type: 'string',
            description: 'Code to execute'
          },
          language: {
            type: 'string',
            enum: ['python', 'javascript', 'typescript'],
            default: 'python'
          }
        },
        required: ['code']
      }
    }
  }
}

// åˆ›å»ºç¼–ç ä»£ç†
class CodingAgent extends Agent {
  private e2bTool: E2BTool
  
  constructor() {
    super({
      name: 'CodingAgent',
      description: 'An agent specialized in writing and executing code',
      model: 'gpt-4'
    })
    
    this.e2bTool = new E2BTool()
    this.registerTool(this.e2bTool)
  }
  
  async initialize() {
    await this.e2bTool.initialize()
  }
  
  async processTask(task: Task): Promise<any> {
    // åˆ†æä»»åŠ¡
    const analysis = await this.analyzeTask(task)
    
    // ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
    const solution = await this.generateSolution(analysis)
    
    // æ‰§è¡Œå’ŒéªŒè¯
    const result = await this.executeAndValidate(solution)
    
    return result
  }
  
  private async analyzeTask(task: Task) {
    const prompt = `
    Analyze this coding task:
    ${task.description}
    
    Provide:
    1. Required functionality
    2. Suggested approach
    3. Potential challenges
    4. Success criteria
    `
    
    return await this.complete(prompt)
  }
  
  private async generateSolution(analysis: string) {
    const prompt = `
    Based on this analysis:
    ${analysis}
    
    Generate complete, production-ready code that:
    1. Implements all requirements
    2. Includes error handling
    3. Has proper documentation
    4. Follows best practices
    `
    
    return await this.complete(prompt)
  }
  
  private async executeAndValidate(solution: string) {
    // æå–ä»£ç 
    const code = this.extractCode(solution)
    
    // æ‰§è¡Œä»£ç 
    const result = await this.e2bTool.execute({ code })
    
    // å¦‚æœå¤±è´¥ï¼Œå°è¯•ä¿®å¤
    if (!result.success) {
      const fixedCode = await this.fixCode(code, result.error)
      return await this.e2bTool.execute({ code: fixedCode })
    }
    
    return result
  }
  
  private extractCode(text: string): string {
    const codeBlockRegex = /```(?:python|javascript|typescript)?\n([\s\S]*?)\n```/g
    const matches = [...text.matchAll(codeBlockRegex)]
    return matches.map(m => m[1]).join('\n\n')
  }
  
  private async fixCode(code: string, error: string): Promise<string> {
    const prompt = `
    This code has an error:
    
    Code:
    ${code}
    
    Error:
    ${error}
    
    Fix the code and return the corrected version.
    `
    
    const response = await this.complete(prompt)
    return this.extractCode(response)
  }
  
  async cleanup() {
    await this.e2bTool.cleanup()
  }
}

// ä½¿ç”¨ç¤ºä¾‹
async function agentKitDemo() {
  const agent = new CodingAgent()
  await agent.initialize()
  
  try {
    // åˆ›å»ºä»»åŠ¡
    const task = new Task({
      description: `
        Create a web scraper that:
        1. Fetches the top stories from Hacker News
        2. Extracts title, URL, points, and comments
        3. Saves data to CSV and JSON formats
        4. Creates a summary visualization
      `,
      requirements: [
        'Use appropriate libraries',
        'Handle errors gracefully',
        'Include rate limiting',
        'Generate clean output files'
      ]
    })
    
    // æ‰§è¡Œä»»åŠ¡
    const result = await agent.processTask(task)
    
    console.log('Task completed!')
    console.log('Output:', result.output)
    console.log('Files generated:', result.artifacts)
    
  } finally {
    await agent.cleanup()
  }
}
```

### é«˜çº§ AgentKit å·¥ä½œæµ

```typescript
import { Workflow, Stage, Condition } from '@agentkit/workflow'
import { CodingAgent, ReviewAgent, TestAgent } from './agents'

class DevelopmentWorkflow extends Workflow {
  constructor() {
    super({
      name: 'DevelopmentWorkflow',
      description: 'Complete software development workflow'
    })
    
    this.setupStages()
  }
  
  private setupStages() {
    // é˜¶æ®µ 1: éœ€æ±‚åˆ†æ
    this.addStage(new Stage({
      name: 'requirements_analysis',
      agent: new RequirementsAgent(),
      inputs: ['user_requirements'],
      outputs: ['technical_spec']
    }))
    
    // é˜¶æ®µ 2: æ¶æ„è®¾è®¡
    this.addStage(new Stage({
      name: 'architecture_design',
      agent: new ArchitectureAgent(),
      inputs: ['technical_spec'],
      outputs: ['architecture_doc', 'component_list']
    }))
    
    // é˜¶æ®µ 3: å¹¶è¡Œå¼€å‘
    this.addParallelStages([
      new Stage({
        name: 'backend_development',
        agent: new BackendAgent(),
        inputs: ['architecture_doc'],
        outputs: ['backend_code']
      }),
      new Stage({
        name: 'frontend_development',
        agent: new FrontendAgent(),
        inputs: ['architecture_doc'],
        outputs: ['frontend_code']
      })
    ])
    
    // é˜¶æ®µ 4: é›†æˆæµ‹è¯•
    this.addStage(new Stage({
      name: 'integration',
      agent: new IntegrationAgent(),
      inputs: ['backend_code', 'frontend_code'],
      outputs: ['integrated_app']
    }))
    
    // é˜¶æ®µ 5: æµ‹è¯•
    this.addStage(new Stage({
      name: 'testing',
      agent: new TestAgent(),
      inputs: ['integrated_app'],
      outputs: ['test_results']
    }))
    
    // æ¡ä»¶åˆ†æ”¯
    this.addCondition(new Condition({
      name: 'check_tests',
      evaluate: (context) => {
        const testResults = context.get('test_results')
        return testResults.passed ? 'deploy' : 'fix_issues'
      }
    }))
    
    // é˜¶æ®µ 6A: ä¿®å¤é—®é¢˜
    this.addStage(new Stage({
      name: 'fix_issues',
      agent: new DebugAgent(),
      inputs: ['test_results', 'integrated_app'],
      outputs: ['fixed_app'],
      nextStage: 'testing'  // è¿”å›æµ‹è¯•
    }))
    
    // é˜¶æ®µ 6B: éƒ¨ç½²
    this.addStage(new Stage({
      name: 'deploy',
      agent: new DeploymentAgent(),
      inputs: ['integrated_app'],
      outputs: ['deployment_url', 'deployment_report']
    }))
  }
  
  async execute(requirements: string) {
    const context = new WorkflowContext()
    context.set('user_requirements', requirements)
    
    return await this.run(context)
  }
}

// ä¸“é—¨çš„ E2B å¢å¼ºä»£ç†
class E2BEnhancedAgent extends Agent {
  private sandboxPool: SandboxPool
  
  constructor(config: AgentConfig) {
    super(config)
    this.sandboxPool = new SandboxPool(3)  // 3 ä¸ªå¹¶å‘æ²™ç®±
  }
  
  async initialize() {
    await this.sandboxPool.initialize()
  }
  
  async executeWithDependencies(code: string, dependencies: string[]) {
    const sandbox = await this.sandboxPool.acquire()
    
    try {
      // å®‰è£…ä¾èµ–
      if (dependencies.length > 0) {
        const installCmd = `pip install ${dependencies.join(' ')}`
        await sandbox.runCode(`
import subprocess
subprocess.run("${installCmd}".split(), check=True)
print("Dependencies installed successfully")
`)
      }
      
      // æ‰§è¡Œä¸»ä»£ç 
      const result = await sandbox.runCode(code)
      
      // æ”¶é›†è¾“å‡ºæ–‡ä»¶
      const artifacts = []
      if (result.artifacts) {
        for (const artifact of result.artifacts) {
          const content = await sandbox.downloadFile(artifact.path)
          artifacts.push({
            name: artifact.name,
            content: content,
            type: artifact.type
          })
        }
      }
      
      return {
        success: !result.error,
        output: result.logs.stdout,
        error: result.error,
        artifacts
      }
      
    } finally {
      await this.sandboxPool.release(sandbox)
    }
  }
  
  async runTests(code: string, testCode: string) {
    const sandbox = await this.sandboxPool.acquire()
    
    try {
      // ä¿å­˜ä¸»ä»£ç 
      await sandbox.writeFile('/tmp/main.py', code)
      
      // ä¿å­˜æµ‹è¯•ä»£ç 
      await sandbox.writeFile('/tmp/test_main.py', testCode)
      
      // è¿è¡Œæµ‹è¯•
      const testResult = await sandbox.runCode(`
import subprocess
import json

# è¿è¡Œ pytest
result = subprocess.run(
    ['pytest', '/tmp/test_main.py', '-v', '--json-report', '--json-report-file=/tmp/test_report.json'],
    capture_output=True,
    text=True
)

# è¯»å–æµ‹è¯•æŠ¥å‘Š
with open('/tmp/test_report.json', 'r') as f:
    report = json.load(f)

print(f"Tests passed: {report['summary']['passed']}")
print(f"Tests failed: {report['summary']['failed']}")
print(f"Total tests: {report['summary']['total']}")

# è¿”å›æµ‹è¯•æ˜¯å¦å…¨éƒ¨é€šè¿‡
success = report['summary']['failed'] == 0
`)
      
      const report = await sandbox.downloadFile('/tmp/test_report.json')
      
      return {
        success: testResult.logs.stdout.includes('success = True'),
        report: JSON.parse(report),
        output: testResult.logs.stdout
      }
      
    } finally {
      await this.sandboxPool.release(sandbox)
    }
  }
}

// ä½¿ç”¨ç¤ºä¾‹
async function advancedAgentKitDemo() {
  const workflow = new DevelopmentWorkflow()
  
  const result = await workflow.execute(`
    Build a real-time dashboard application that:
    1. Monitors system metrics (CPU, memory, disk)
    2. Displays data in interactive charts
    3. Sends alerts when thresholds are exceeded
    4. Has both web interface and API
    5. Includes user authentication
  `)
  
  console.log('Workflow completed!')
  console.log('Deployment URL:', result.deployment_url)
  console.log('Full report:', result.deployment_report)
}
```

## æ¡†æ¶å¯¹æ¯”ä¸é€‰æ‹©

### å¯¹æ¯”è¡¨

| ç‰¹æ€§ | LangChain | LangGraph | Autogen | Vercel AI SDK | AgentKit |
|------|-----------|-----------|---------|---------------|----------|
| **ä¸»è¦ç”¨é€”** | LLM åº”ç”¨å¼€å‘ | å·¥ä½œæµç¼–æ’ | å¤šä»£ç†åä½œ | Web AI åº”ç”¨ | ç¼–ç ä»»åŠ¡ |
| **å¤æ‚åº¦** | ä¸­ç­‰ | é«˜ | é«˜ | ä½ | ä¸­ç­‰ |
| **å­¦ä¹ æ›²çº¿** | å¹³ç¼“ | é™¡å³­ | ä¸­ç­‰ | å¹³ç¼“ | ä¸­ç­‰ |
| **E2B é›†æˆ** | å·¥å…·æ–¹å¼ | èŠ‚ç‚¹æ–¹å¼ | æ‰§è¡Œå™¨æ–¹å¼ | API æ–¹å¼ | åŸç”Ÿæ”¯æŒ |
| **æœ€é€‚åˆ** | é€šç”¨ AI åº”ç”¨ | å¤æ‚å·¥ä½œæµ | å›¢é˜Ÿåä½œæ¨¡æ‹Ÿ | Web åº”ç”¨ | ä»£ç ç”Ÿæˆ |
| **æ€§èƒ½** | è‰¯å¥½ | è‰¯å¥½ | ä¸­ç­‰ | ä¼˜ç§€ | è‰¯å¥½ |
| **ç¤¾åŒºæ”¯æŒ** | ä¼˜ç§€ | è‰¯å¥½ | è‰¯å¥½ | ä¼˜ç§€ | å‘å±•ä¸­ |

### é€‰æ‹©å»ºè®®

1. **é€‰æ‹© LangChain**ï¼š
   - éœ€è¦å¿«é€ŸåŸå‹å¼€å‘
   - æ„å»ºé€šç”¨ AI åº”ç”¨
   - éœ€è¦ä¸°å¯Œçš„å·¥å…·ç”Ÿæ€

2. **é€‰æ‹© LangGraph**ï¼š
   - éœ€è¦å¤æ‚çš„çŠ¶æ€ç®¡ç†
   - æ„å»ºå¤šæ­¥éª¤å·¥ä½œæµ
   - éœ€è¦æ¡ä»¶åˆ†æ”¯å’Œå¾ªç¯

3. **é€‰æ‹© Autogen**ï¼š
   - æ¨¡æ‹Ÿå›¢é˜Ÿåä½œ
   - éœ€è¦å¤šä¸ªä¸“ä¸šä»£ç†
   - æ„å»ºè‡ªä¸»ä»£ç†ç³»ç»Ÿ

4. **é€‰æ‹© Vercel AI SDK**ï¼š
   - æ„å»º Web åº”ç”¨
   - éœ€è¦æµå¼å“åº”
   - é‡è§†ç”¨æˆ·ä½“éªŒ

5. **é€‰æ‹© AgentKit**ï¼š
   - ä¸“æ³¨ä»£ç ç”Ÿæˆ
   - éœ€è¦ä»£ç è´¨é‡ä¿è¯
   - æ„å»ºå¼€å‘å·¥å…·

## é«˜çº§é›†æˆæ¨¡å¼

### 1. æ··åˆæ¡†æ¶æ¶æ„

```python
from langchain.agents import Tool
from langgraph.graph import Graph
import autogen
from e2b_code_interpreter import Sandbox

class HybridAISystem:
    """æ··åˆå¤šä¸ª AI æ¡†æ¶çš„ç³»ç»Ÿ"""
    
    def __init__(self):
        # LangChain ç”¨äºå·¥å…·ç®¡ç†
        self.tools = self._create_langchain_tools()
        
        # LangGraph ç”¨äºå·¥ä½œæµ
        self.workflow = self._create_langgraph_workflow()
        
        # Autogen ç”¨äºå¤šä»£ç†
        self.agents = self._create_autogen_agents()
        
        # E2B ä½œä¸ºç»Ÿä¸€æ‰§è¡Œå±‚
        self.execution_layer = E2BExecutionLayer()
    
    async def process_request(self, request: str):
        """å¤„ç†å¤æ‚è¯·æ±‚"""
        
        # 1. ä½¿ç”¨ LangChain åˆ†æè¯·æ±‚
        analysis = await self.analyze_with_langchain(request)
        
        # 2. æ ¹æ®åˆ†æç»“æœé€‰æ‹©å·¥ä½œæµ
        if analysis['complexity'] == 'high':
            # ä½¿ç”¨ LangGraph å¤„ç†å¤æ‚å·¥ä½œæµ
            result = await self.workflow.run(analysis)
        elif analysis['requires_collaboration']:
            # ä½¿ç”¨ Autogen è¿›è¡Œå¤šä»£ç†åä½œ
            result = await self.run_autogen_collaboration(analysis)
        else:
            # ç›´æ¥æ‰§è¡Œ
            result = await self.execution_layer.execute(analysis['code'])
        
        return result
```

### 2. ç»Ÿä¸€ç›‘æ§å’Œæ—¥å¿—

```typescript
import { EventEmitter } from 'events'

class UnifiedMonitor extends EventEmitter {
  private metrics: Map<string, any> = new Map()
  
  trackExecution(framework: string, executionId: string, data: any) {
    const key = `${framework}:${executionId}`
    
    this.metrics.set(key, {
      framework,
      executionId,
      startTime: Date.now(),
      ...data
    })
    
    this.emit('execution:start', { framework, executionId, data })
  }
  
  updateExecution(framework: string, executionId: string, update: any) {
    const key = `${framework}:${executionId}`
    const existing = this.metrics.get(key)
    
    if (existing) {
      this.metrics.set(key, { ...existing, ...update })
      this.emit('execution:update', { framework, executionId, update })
    }
  }
  
  completeExecution(framework: string, executionId: string, result: any) {
    const key = `${framework}:${executionId}`
    const existing = this.metrics.get(key)
    
    if (existing) {
      const duration = Date.now() - existing.startTime
      
      this.metrics.set(key, {
        ...existing,
        endTime: Date.now(),
        duration,
        result,
        status: 'completed'
      })
      
      this.emit('execution:complete', {
        framework,
        executionId,
        duration,
        result
      })
    }
  }
  
  getMetrics() {
    return Array.from(this.metrics.values())
  }
}
```

### 3. é”™è¯¯æ¢å¤å’Œé‡è¯•ç­–ç•¥

```python
class ResilientE2BIntegration:
    """å¼¹æ€§ E2B é›†æˆ"""
    
    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
        self.fallback_strategies = []
    
    def add_fallback(self, strategy):
        """æ·»åŠ é™çº§ç­–ç•¥"""
        self.fallback_strategies.append(strategy)
    
    async def execute_with_resilience(self, code: str, context: dict):
        """å¼¹æ€§æ‰§è¡Œ"""
        
        errors = []
        
        # ä¸»æ‰§è¡Œå°è¯•
        for attempt in range(self.max_retries):
            try:
                sandbox = await Sandbox.create()
                result = await sandbox.run_code(code)
                
                if not result.error:
                    return result
                    
                errors.append({
                    'attempt': attempt + 1,
                    'error': result.error
                })
                
                # å°è¯•è‡ªåŠ¨ä¿®å¤
                if attempt < self.max_retries - 1:
                    code = await self.auto_fix_code(code, result.error)
                    
            except Exception as e:
                errors.append({
                    'attempt': attempt + 1,
                    'error': str(e)
                })
            finally:
                if 'sandbox' in locals():
                    await sandbox.kill()
        
        # æ‰§è¡Œé™çº§ç­–ç•¥
        for strategy in self.fallback_strategies:
            try:
                return await strategy(code, context, errors)
            except:
                continue
        
        raise Exception(f"All attempts failed: {errors}")
    
    async def auto_fix_code(self, code: str, error: str) -> str:
        """è‡ªåŠ¨ä¿®å¤ä»£ç """
        # ä½¿ç”¨ LLM å°è¯•ä¿®å¤
        prompt = f"""
        Fix this Python code that has the following error:
        
        Code:
        {code}
        
        Error:
        {error}
        
        Return only the fixed code.
        """
        
        # è°ƒç”¨ LLM è·å–ä¿®å¤
        fixed_code = await self.llm_fix(prompt)
        return fixed_code
```

## æœ€ä½³å®è·µæ€»ç»“

1. **é€‰æ‹©åˆé€‚çš„æ¡†æ¶**ï¼š
   - æ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©æ¡†æ¶
   - å¯ä»¥ç»„åˆä½¿ç”¨å¤šä¸ªæ¡†æ¶
   - E2B ä½œä¸ºç»Ÿä¸€çš„æ‰§è¡Œå±‚

2. **èµ„æºç®¡ç†**ï¼š
   - ä½¿ç”¨æ²™ç®±æ± æé«˜æ€§èƒ½
   - åŠæ—¶æ¸…ç†èµ„æº
   - å®ç°ä¼˜é›…çš„é”™è¯¯å¤„ç†

3. **å®‰å…¨è€ƒè™‘**ï¼š
   - éªŒè¯æ‰€æœ‰è¾“å…¥ä»£ç 
   - é™åˆ¶èµ„æºä½¿ç”¨
   - å®ç°è®¿é—®æ§åˆ¶

4. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - ç¼“å­˜å¸¸ç”¨ç»“æœ
   - å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
   - ä½¿ç”¨æµå¼å“åº”

5. **ç›‘æ§å’Œè°ƒè¯•**ï¼š
   - ç»Ÿä¸€æ—¥å¿—æ ¼å¼
   - è¿½è¸ªæ‰§è¡Œé“¾è·¯
   - æ”¶é›†æ€§èƒ½æŒ‡æ ‡

é€šè¿‡åˆç†é›†æˆè¿™äº› AI æ¡†æ¶å’Œ E2Bï¼Œä½ å¯ä»¥æ„å»ºåŠŸèƒ½å¼ºå¤§ã€å¯æ‰©å±•çš„ AI åº”ç”¨ï¼Œå……åˆ†å‘æŒ¥å„æ¡†æ¶çš„ä¼˜åŠ¿ï¼Œä¸ºç”¨æˆ·æä¾›å“è¶Šçš„ä½“éªŒã€‚