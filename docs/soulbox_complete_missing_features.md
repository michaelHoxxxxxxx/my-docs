# SoulBox å®Œæ•´ç¼ºå¤±åŠŸèƒ½æ¸…å•

> æœ¬æ–‡æ¡£æ•´åˆäº†æ‰€æœ‰å·²å‘ç°çš„ç¼ºå¤±åŠŸèƒ½ï¼Œå…±è®¡ 22 ä¸ªï¼Œä½œä¸º SoulBox é¡¹ç›®çš„å¼€å‘æŒ‡å—

---

## ğŸ“‹ åŠŸèƒ½åˆ†ç±»æ¦‚è§ˆ

| ç±»åˆ« | åŠŸèƒ½æ•°é‡ | ä¼˜å…ˆçº§ |
|------|----------|--------|
| **åŸºç¡€åŠŸèƒ½è¡¥å……** | 10ä¸ª | P0-P1 |
| **è®¤è¯ä¸å®‰å…¨** | 2ä¸ª | P0 |
| **æ€§èƒ½ä¼˜åŒ–** | 2ä¸ª | P0 |
| **å¼€å‘è€…ä½“éªŒ** | 2ä¸ª | P1 |
| **ç½‘ç»œå¢å¼º** | 2ä¸ª | P1 |
| **å­˜å‚¨åŠŸèƒ½** | 2ä¸ª | P2 |
| **ä¼ä¸šåŠŸèƒ½** | 2ä¸ª | P2 |

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€åŠŸèƒ½è¡¥å……ï¼ˆåŸ 10 ä¸ªåŠŸèƒ½ï¼‰

### 1. å¥åº·æ£€æŸ¥ç«¯ç‚¹

E2B æä¾›äº† `/health` ç«¯ç‚¹ç”¨äºæ£€æŸ¥æ²™ç®±çŠ¶æ€ã€‚

#### Rust å®ç°

```rust
use axum::{
    http::StatusCode,
    response::IntoResponse,
    Json,
};
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct HealthResponse {
    pub status: String,
    pub sandbox_id: String,
    pub uptime_seconds: u64,
    pub version: String,
}

impl SoulBox {
    /// å¥åº·æ£€æŸ¥
    pub async fn health_check(&self) -> Result<HealthResponse, SoulBoxError> {
        let uptime = self.started_at.elapsed()?.as_secs();
        
        Ok(HealthResponse {
            status: "healthy".to_string(),
            sandbox_id: self.id.to_string(),
            uptime_seconds: uptime,
            version: env!("CARGO_PKG_VERSION").to_string(),
        })
    }
}

// API ç«¯ç‚¹
pub async fn health_handler(
    State(sandbox): State<Arc<SoulBox>>,
) -> impl IntoResponse {
    match sandbox.health_check().await {
        Ok(health) => (StatusCode::OK, Json(health)),
        Err(_) => (
            StatusCode::SERVICE_UNAVAILABLE,
            Json(serde_json::json!({
                "status": "unhealthy"
            }))
        ),
    }
}
```

### 2. æ–‡ä»¶ç­¾åå’Œå®‰å…¨ URL

E2B æ”¯æŒç”Ÿæˆå¸¦ç­¾åçš„ä¸Šä¼ /ä¸‹è½½ URLï¼Œç”¨äºå®‰å…¨çš„æ–‡ä»¶ä¼ è¾“ã€‚

#### Rust å®ç°

```rust
use hmac::{Hmac, Mac};
use sha2::Sha256;
use base64::Engine;

#[derive(Debug, Clone)]
pub struct FileSignature {
    pub signature: String,
    pub expiration: Option<i64>,
}

#[derive(Debug, Clone)]
pub struct SignatureOptions {
    pub path: String,
    pub operation: FileOperation,
    pub user: Username,
    pub expiration_in_seconds: Option<u64>,
}

#[derive(Debug, Clone, PartialEq)]
pub enum FileOperation {
    Read,
    Write,
}

impl SoulBox {
    /// ç”Ÿæˆæ–‡ä»¶æ“ä½œç­¾å
    pub async fn generate_signature(
        &self,
        opts: SignatureOptions,
    ) -> Result<FileSignature, SoulBoxError> {
        let secret = self.envd_access_token.as_ref()
            .ok_or(SoulBoxError::SecurityViolation("No access token".into()))?;
        
        let expiration = opts.expiration_in_seconds
            .map(|secs| Utc::now().timestamp() + secs as i64);
        
        // æ„å»ºç­¾åå†…å®¹
        let mut content = format!(
            "{}:{}:{}",
            opts.path,
            match opts.operation {
                FileOperation::Read => "read",
                FileOperation::Write => "write",
            },
            opts.user
        );
        
        if let Some(exp) = expiration {
            content.push_str(&format!(":{}", exp));
        }
        
        // ç”Ÿæˆ HMAC ç­¾å
        let mut mac = Hmac::<Sha256>::new_from_slice(secret.as_bytes())?;
        mac.update(content.as_bytes());
        let signature = base64::engine::general_purpose::URL_SAFE_NO_PAD
            .encode(mac.finalize().into_bytes());
        
        Ok(FileSignature {
            signature,
            expiration,
        })
    }
}
```

### 3. ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥

E2B SDK åŒ…å«ç‰ˆæœ¬å…¼å®¹æ€§é€»è¾‘ï¼Œç¡®ä¿å®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯ç‰ˆæœ¬åŒ¹é…ã€‚

#### Rust å®ç°

```rust
use semver::{Version, VersionReq};

pub const ENVD_VERSION_RECURSIVE_WATCH: &str = "0.1.4";
pub const MIN_SUPPORTED_VERSION: &str = "0.1.0";
pub const CURRENT_API_VERSION: &str = "v1";

#[derive(Debug, Clone)]
pub struct VersionInfo {
    pub envd_version: Option<Version>,
    pub api_version: String,
    pub sdk_version: Version,
}

impl SoulBox {
    /// æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
    pub fn check_version_compatibility(&self) -> Result<(), SoulBoxError> {
        if let Some(ref envd_version) = self.version_info.envd_version {
            let min_version = Version::parse(MIN_SUPPORTED_VERSION)?;
            
            if envd_version < &min_version {
                return Err(SoulBoxError::VersionMismatch(format!(
                    "Envd version {} is too old. Minimum supported version is {}",
                    envd_version, min_version
                )));
            }
        }
        
        Ok(())
    }
}
```

### 4. è‡ªåŠ¨æš‚åœåŠŸèƒ½

E2B æ”¯æŒåœ¨è¶…æ—¶åè‡ªåŠ¨æš‚åœæ²™ç®±è€Œä¸æ˜¯ç»ˆæ­¢ã€‚

#### Rust å®ç°

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeoutBehavior {
    pub auto_pause: bool,
    pub grace_period_ms: Option<u64>,
}

impl SoulBox {
    /// è®¾ç½®è¶…æ—¶è¡Œä¸º
    pub async fn set_timeout_behavior(
        &self,
        timeout_ms: u64,
        behavior: TimeoutBehavior,
    ) -> Result<(), SoulBoxError> {
        // å–æ¶ˆç°æœ‰çš„è¶…æ—¶ä»»åŠ¡
        if let Some(handle) = self.timeout_handle.lock().await.take() {
            handle.abort();
        }
        
        let sandbox = self.clone();
        let handle = tokio::spawn(async move {
            tokio::time::sleep(Duration::from_millis(timeout_ms)).await;
            
            if behavior.auto_pause {
                // æš‚åœè€Œä¸æ˜¯ç»ˆæ­¢
                if let Err(e) = sandbox.pause().await {
                    error!("Failed to auto-pause sandbox: {}", e);
                } else {
                    info!("Sandbox {} auto-paused after timeout", sandbox.id);
                }
            } else {
                // ç›´æ¥ç»ˆæ­¢
                if let Err(e) = sandbox.terminate().await {
                    error!("Failed to terminate sandbox: {}", e);
                }
            }
        });
        
        *self.timeout_handle.lock().await = Some(handle);
        
        Ok(())
    }
}
```

### 5. å‘½ä»¤ç»“æœçš„éƒ¨åˆ†è¾“å‡ºè·å–

E2B çš„ CommandHandle æ”¯æŒåœ¨å‘½ä»¤æ‰§è¡Œè¿‡ç¨‹ä¸­è·å–éƒ¨åˆ†è¾“å‡ºã€‚

#### Rust å®ç°

```rust
use tokio::sync::watch;

pub struct CommandHandle {
    pid: u32,
    stdout: Arc<Mutex<String>>,
    stderr: Arc<Mutex<String>>,
    exit_code: watch::Receiver<Option<i32>>,
    result_tx: watch::Sender<Option<i32>>,
}

impl CommandHandle {
    /// è·å–å½“å‰çš„ stdoutï¼ˆä¸ç­‰å¾…å‘½ä»¤å®Œæˆï¼‰
    pub async fn get_stdout(&self) -> String {
        self.stdout.lock().await.clone()
    }
    
    /// è·å–å½“å‰çš„ stderrï¼ˆä¸ç­‰å¾…å‘½ä»¤å®Œæˆï¼‰
    pub async fn get_stderr(&self) -> String {
        self.stderr.lock().await.clone()
    }
    
    /// æ£€æŸ¥å‘½ä»¤æ˜¯å¦å·²å®Œæˆ
    pub fn is_finished(&self) -> bool {
        self.exit_code.borrow().is_some()
    }
}
```

### 6. è¿æ¥é‡å®šå‘æ”¯æŒ

E2B åœ¨è¿æ¥æ—¶æ”¯æŒé‡å®šå‘ï¼Œè¿™å¯¹äºè¾¹ç¼˜è¿è¡Œæ—¶å¾ˆé‡è¦ã€‚

#### Rust å®ç°

```rust
use reqwest::{Client, redirect::Policy};

pub struct ConnectionConfig {
    pub follow_redirects: bool,
    pub max_redirects: usize,
}

impl Default for ConnectionConfig {
    fn default() -> Self {
        Self {
            follow_redirects: true,
            max_redirects: 10,
        }
    }
}

impl SoulBox {
    /// åˆ›å»º HTTP å®¢æˆ·ç«¯
    fn create_http_client(config: &ConnectionConfig) -> Result<Client, SoulBoxError> {
        let mut builder = Client::builder();
        
        if config.follow_redirects {
            builder = builder.redirect(Policy::limited(config.max_redirects));
        } else {
            builder = builder.redirect(Policy::none());
        }
        
        Ok(builder
            .timeout(Duration::from_millis(config.request_timeout_ms))
            .build()?)
    }
}
```

### 7. æ²™ç®±åˆ·æ–°æœºåˆ¶

E2B æ”¯æŒåˆ·æ–°æ²™ç®±ä»¥å»¶é•¿å…¶ç”Ÿå‘½å‘¨æœŸã€‚

#### Rust å®ç°

```rust
#[derive(Debug, Serialize, Deserialize)]
pub struct RefreshOptions {
    pub extend_by_ms: u64,
    pub max_duration_ms: Option<u64>,
}

impl SoulBox {
    /// åˆ·æ–°æ²™ç®±ï¼Œå»¶é•¿å…¶ç”Ÿå‘½å‘¨æœŸ
    pub async fn refresh(
        &self,
        opts: RefreshOptions,
    ) -> Result<DateTime<Utc>, SoulBoxError> {
        // è®¡ç®—æ–°çš„ç»“æŸæ—¶é—´
        let current_end = self.end_at.lock().await;
        let new_end = *current_end + Duration::milliseconds(opts.extend_by_ms as i64);
        
        // æ£€æŸ¥æœ€å¤§æŒç»­æ—¶é—´é™åˆ¶
        if let Some(max_duration) = opts.max_duration_ms {
            let max_end = self.started_at + Duration::milliseconds(max_duration as i64);
            if new_end > max_end {
                return Err(SoulBoxError::InvalidArgument(
                    "Cannot extend sandbox beyond maximum duration".into()
                ));
            }
        }
        
        // æ›´æ–°ç»“æŸæ—¶é—´
        *self.end_at.lock().await = new_end;
        
        Ok(new_end)
    }
}
```

### 8. æ²™ç®±æŒ‡æ ‡è¯¦ç»†ä¿¡æ¯

E2B æä¾›äº†è¯¦ç»†çš„æ²™ç®±æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ CPUã€å†…å­˜ã€ç½‘ç»œç­‰ã€‚

#### Rust å®ç°

```rust
use sysinfo::{System, SystemExt, ProcessExt};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SandboxMetric {
    pub timestamp: DateTime<Utc>,
    pub cpu_percent: f64,
    pub memory_bytes: u64,
    pub memory_percent: f64,
    pub disk_read_bytes: u64,
    pub disk_write_bytes: u64,
    pub network_rx_bytes: u64,
    pub network_tx_bytes: u64,
    pub process_count: u32,
}

pub struct MetricsCollector {
    system: System,
    sandbox_id: Uuid,
    interval: Duration,
    metrics: Arc<Mutex<Vec<SandboxMetric>>>,
}

impl MetricsCollector {
    /// å¼€å§‹æ”¶é›†æŒ‡æ ‡
    pub fn start(sandbox_id: Uuid, interval: Duration) -> Self {
        let collector = Self {
            system: System::new_all(),
            sandbox_id,
            interval,
            metrics: Arc::new(Mutex::new(Vec::new())),
        };
        
        collector
    }
    
    /// è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„æŒ‡æ ‡
    pub async fn get_metrics(
        &self,
        start: Option<DateTime<Utc>>,
        end: Option<DateTime<Utc>>,
    ) -> Vec<SandboxMetric> {
        let metrics = self.metrics.lock().await;
        
        metrics.iter()
            .filter(|m| {
                let after_start = start.map_or(true, |s| m.timestamp >= s);
                let before_end = end.map_or(true, |e| m.timestamp <= e);
                after_start && before_end
            })
            .cloned()
            .collect()
    }
}
```

### 9. æ¨¡æ¿æ„å»ºæ—¥å¿—æµ

E2B åœ¨æ„å»ºæ¨¡æ¿æ—¶æ”¯æŒå®æ—¶æ—¥å¿—æµã€‚

#### Rust å®ç°

```rust
use tokio::sync::mpsc;
use futures::stream::Stream;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BuildLog {
    pub timestamp: DateTime<Utc>,
    pub level: LogLevel,
    pub message: String,
    pub step: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum LogLevel {
    Debug,
    Info,
    Warning,
    Error,
}

impl TemplateBuilder {
    /// æ„å»ºæ¨¡æ¿å¹¶æµå¼è¿”å›æ—¥å¿—
    pub fn build_stream(
        &self,
    ) -> (impl Stream<Item = BuildLog>, JoinHandle<Result<TemplateImage, SoulBoxError>>) {
        let (tx, rx) = mpsc::channel(100);
        
        let handle = tokio::spawn(async move {
            // Docker æ„å»ºé€»è¾‘
            Ok(TemplateImage::default())
        });
        
        (ReceiverStream::new(rx), handle)
    }
}
```

### 10. èŠ‚ç‚¹å¥åº·çŠ¶æ€

E2B è·Ÿè¸ªæ²™ç®±è¿è¡Œçš„èŠ‚ç‚¹çŠ¶æ€ã€‚

#### Rust å®ç°

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum NodeStatus {
    Healthy,
    Degraded,
    Draining,
    Connecting,
    Unhealthy,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeInfo {
    pub node_id: String,
    pub status: NodeStatus,
    pub cpu_count: u32,
    pub memory_mb: u32,
    pub available_cpu: f32,
    pub available_memory_mb: u32,
    pub sandbox_count: u32,
    pub region: String,
    pub last_health_check: DateTime<Utc>,
}

pub struct NodeManager {
    nodes: Arc<Mutex<HashMap<String, NodeInfo>>>,
}

impl NodeManager {
    /// é€‰æ‹©æœ€ä½³èŠ‚ç‚¹æ¥è¿è¡Œæ²™ç®±
    pub async fn select_node(
        &self,
        requirements: &SandboxConfig,
    ) -> Result<String, SoulBoxError> {
        let nodes = self.nodes.lock().await;
        
        let suitable_nodes: Vec<_> = nodes
            .values()
            .filter(|node| {
                node.status == NodeStatus::Healthy &&
                node.available_cpu >= requirements.cpu_quota &&
                node.available_memory_mb >= (requirements.memory_limit / 1024 / 1024) as u32
            })
            .collect();
        
        if suitable_nodes.is_empty() {
            return Err(SoulBoxError::NoAvailableNodes);
        }
        
        // é€‰æ‹©è´Ÿè½½æœ€ä½çš„èŠ‚ç‚¹
        let best_node = suitable_nodes
            .into_iter()
            .min_by_key(|node| node.sandbox_count)
            .unwrap();
        
        Ok(best_node.node_id.clone())
    }
}
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ–°å‘ç°çš„ç¼ºå¤±åŠŸèƒ½ï¼ˆ12 ä¸ªï¼‰

### 11. å¤šå±‚è®¤è¯æœºåˆ¶ â­â­â­â­â­

E2B å®ç°äº†å®Œæ•´çš„è®¤è¯é“¾ï¼ŒåŒ…æ‹¬ API å¯†é’¥ã€JWTã€mTLS ç­‰å¤šç§è®¤è¯æ–¹å¼ã€‚

#### è®¾è®¡ç›®æ ‡
- æ”¯æŒå¤šç§è®¤è¯æ–¹å¼
- è®¤è¯é“¾å¼éªŒè¯
- ç»†ç²’åº¦çš„æƒé™æ§åˆ¶
- å®‰å…¨ä»¤ç‰Œç®¡ç†

#### Rust å®ç°

```rust
use jsonwebtoken::{decode, encode, DecodingKey, EncodingKey, Header, Validation};
use rustls::ServerConfig;

pub struct AuthenticationLayer {
    // API å¯†é’¥è®¤è¯
    api_key_store: Arc<Mutex<HashMap<String, ApiKeyInfo>>>,
    // JWT ä»¤ç‰Œè®¤è¯
    jwt_secret: String,
    // mTLS åŒå‘è®¤è¯
    tls_config: Option<ServerConfig>,
    // OAuth2 é›†æˆ
    oauth2_providers: HashMap<String, OAuth2Config>,
}

#[derive(Debug, Clone)]
pub struct ApiKeyInfo {
    pub key_id: String,
    pub user_id: UserId,
    pub permissions: Vec<Permission>,
    pub created_at: DateTime<Utc>,
    pub expires_at: Option<DateTime<Utc>>,
    pub last_used: Option<DateTime<Utc>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct JwtClaims {
    pub sub: String,
    pub exp: i64,
    pub iat: i64,
    pub permissions: Vec<String>,
}

impl AuthenticationLayer {
    /// éªŒè¯è¯·æ±‚çš„è®¤è¯ä¿¡æ¯
    pub async fn authenticate_request(
        &self,
        req: &Request,
    ) -> Result<AuthContext, AuthError> {
        // å°è¯•å¤šç§è®¤è¯æ–¹å¼
        
        // 1. API Key è®¤è¯
        if let Some(api_key) = req.headers().get("X-API-Key") {
            if let Ok(context) = self.verify_api_key(api_key.to_str()?).await {
                return Ok(context);
            }
        }
        
        // 2. JWT è®¤è¯
        if let Some(auth_header) = req.headers().get("Authorization") {
            if let Ok(token) = auth_header.to_str() {
                if token.starts_with("Bearer ") {
                    let jwt = &token[7..];
                    if let Ok(context) = self.verify_jwt(jwt).await {
                        return Ok(context);
                    }
                }
            }
        }
        
        // 3. mTLS è®¤è¯
        if let Some(cert) = req.extensions().get::<Certificate>() {
            if let Ok(context) = self.verify_mtls_cert(cert).await {
                return Ok(context);
            }
        }
        
        Err(AuthError::Unauthorized("No valid authentication provided".into()))
    }
    
    /// ç”Ÿæˆæ–°çš„ API å¯†é’¥
    pub async fn generate_api_key(
        &self,
        user_id: UserId,
        permissions: Vec<Permission>,
        expires_in: Option<Duration>,
    ) -> Result<String, AuthError> {
        let key = generate_secure_token(32);
        let key_id = generate_secure_token(16);
        
        let info = ApiKeyInfo {
            key_id: key_id.clone(),
            user_id,
            permissions,
            created_at: Utc::now(),
            expires_at: expires_in.map(|d| Utc::now() + d),
            last_used: None,
        };
        
        self.api_key_store.lock().await.insert(key.clone(), info);
        
        Ok(format!("sb_{}_{}", key_id, key))
    }
}
```

### 12. ç»†ç²’åº¦æƒé™æ§åˆ¶ (RBAC) â­â­â­â­â­

å®ç°åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ç³»ç»Ÿã€‚

#### Rust å®ç°

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Permission {
    pub resource: Resource,
    pub action: Action,
    pub conditions: Vec<Condition>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Resource {
    Sandbox(SandboxId),
    Template(TemplateId),
    File(PathBuf),
    Network(NetworkResource),
    System,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum Action {
    Create,
    Read,
    Update,
    Delete,
    Execute,
    Connect,
    Admin,
}

#[derive(Debug, Clone)]
pub struct Role {
    pub id: RoleId,
    pub name: String,
    pub permissions: Vec<Permission>,
    pub parent_roles: Vec<RoleId>,
}

pub struct RbacManager {
    roles: Arc<Mutex<HashMap<RoleId, Role>>>,
    user_roles: Arc<Mutex<HashMap<UserId, Vec<RoleId>>>>,
}

impl RbacManager {
    /// æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™æ‰§è¡Œæ“ä½œ
    pub async fn check_permission(
        &self,
        user_id: &UserId,
        resource: &Resource,
        action: &Action,
    ) -> Result<(), AuthError> {
        let user_roles = self.user_roles.lock().await;
        let roles = self.roles.lock().await;
        
        let role_ids = user_roles.get(user_id)
            .ok_or_else(|| AuthError::NoRoles)?;
        
        // é€’å½’æ£€æŸ¥æ‰€æœ‰è§’è‰²åŠå…¶çˆ¶è§’è‰²
        for role_id in role_ids {
            if self.role_has_permission(&roles, role_id, resource, action).await? {
                return Ok(());
            }
        }
        
        Err(AuthError::PermissionDenied)
    }
    
    /// ä¸ºç”¨æˆ·åˆ†é…è§’è‰²
    pub async fn assign_role(
        &self,
        user_id: UserId,
        role_id: RoleId,
    ) -> Result<(), AuthError> {
        let mut user_roles = self.user_roles.lock().await;
        user_roles.entry(user_id)
            .or_insert_with(Vec::new)
            .push(role_id);
        Ok(())
    }
}
```

### 13. æ™ºèƒ½æ²™ç®±æ± ç®¡ç† â­â­â­â­â­

é¢„çƒ­æ± æœºåˆ¶å¤§å¹…æå‡å¯åŠ¨é€Ÿåº¦ã€‚

#### è®¾è®¡ç›®æ ‡
- é¢„åˆ›å»ºæ²™ç®±å®ä¾‹
- æ™ºèƒ½é¢„æµ‹å’Œè¡¥å……
- èµ„æºä¼˜åŒ–åˆ©ç”¨
- å¿«é€Ÿå¯åŠ¨å“åº”

#### Rust å®ç°

```rust
pub struct SandboxPool {
    // é¢„çƒ­çš„æ²™ç®±å®ä¾‹
    warm_pool: Arc<Mutex<HashMap<TemplateId, Vec<WarmSandbox>>>>,
    // ä½¿ç”¨ä¸­çš„æ²™ç®±
    active_sandboxes: Arc<Mutex<HashMap<SandboxId, ActiveSandbox>>>,
    // æ± é…ç½®
    config: PoolConfig,
    // è‡ªåŠ¨è¡¥å……ä»»åŠ¡
    refill_handle: Option<JoinHandle<()>>,
    // ç»Ÿè®¡ä¿¡æ¯
    stats: Arc<Mutex<PoolStats>>,
}

#[derive(Debug, Clone)]
pub struct PoolConfig {
    // æ¯ä¸ªæ¨¡æ¿çš„æœ€å°é¢„çƒ­æ•°é‡
    pub min_warm_instances: HashMap<TemplateId, usize>,
    // æœ€å¤§æ± å¤§å°
    pub max_pool_size: usize,
    // é¢„çƒ­ç­–ç•¥
    pub warmup_strategy: WarmupStrategy,
    // è¡¥å……é˜ˆå€¼
    pub refill_threshold: f32,
    // æ± æ¸…ç†é—´éš”
    pub cleanup_interval: Duration,
}

#[derive(Debug, Clone)]
pub enum WarmupStrategy {
    // åŸºäºå†å²ä½¿ç”¨æ¨¡å¼
    Historical { window: Duration },
    // å›ºå®šæ•°é‡
    Fixed { count: usize },
    // åŠ¨æ€è°ƒæ•´
    Dynamic { 
        min: usize,
        max: usize,
        adjustment_rate: f32,
    },
}

#[derive(Debug)]
pub struct WarmSandbox {
    sandbox: Sandbox,
    template_id: TemplateId,
    created_at: DateTime<Utc>,
    warmed_at: DateTime<Utc>,
}

impl SandboxPool {
    /// ä»æ± ä¸­è·å–æˆ–åˆ›å»ºæ²™ç®±
    pub async fn acquire(
        &self,
        template_id: &TemplateId,
        config: Option<SandboxConfig>,
    ) -> Result<Sandbox, SoulBoxError> {
        // è®°å½•è¯·æ±‚
        self.stats.lock().await.record_request(template_id);
        
        // å°è¯•ä»é¢„çƒ­æ± è·å–
        if let Some(warm) = self.get_from_warm_pool(template_id).await? {
            info!("Acquired warm sandbox for template {}", template_id);
            
            // è§¦å‘å¼‚æ­¥è¡¥å……
            self.trigger_refill(template_id).await;
            
            return Ok(warm.activate(config).await?);
        }
        
        // å†·å¯åŠ¨
        info!("Cold starting sandbox for template {}", template_id);
        self.create_cold(template_id, config).await
    }
    
    /// é¢„çƒ­æ²™ç®±
    async fn warmup_sandbox(template_id: &TemplateId) -> Result<WarmSandbox, SoulBoxError> {
        let sandbox = Sandbox::create_minimal(template_id).await?;
        
        // æ‰§è¡Œé¢„çƒ­æ­¥éª¤
        sandbox.preload_runtime().await?;
        sandbox.prepare_filesystem().await?;
        
        Ok(WarmSandbox {
            sandbox,
            template_id: template_id.clone(),
            created_at: Utc::now(),
            warmed_at: Utc::now(),
        })
    }
    
    /// è‡ªåŠ¨è¡¥å……é€»è¾‘
    fn start_refill_task(self: Arc<Self>) {
        let pool = self.clone();
        let handle = tokio::spawn(async move {
            let mut interval = tokio::time::interval(Duration::from_secs(10));
            
            loop {
                interval.tick().await;
                
                if let Err(e) = pool.refill_pools().await {
                    error!("Failed to refill pools: {}", e);
                }
            }
        });
        
        self.refill_handle = Some(handle);
    }
}
```

### 14. åŠ¨æ€èµ„æºè°ƒåº¦å™¨ â­â­â­â­

æ™ºèƒ½åˆ†é…å’Œç®¡ç†ç³»ç»Ÿèµ„æºã€‚

#### Rust å®ç°

```rust
pub struct ResourceScheduler {
    // èŠ‚ç‚¹ç®¡ç†
    node_manager: Arc<NodeManager>,
    // èµ„æºä½¿ç”¨è¿½è¸ª
    resource_tracker: Arc<ResourceTracker>,
    // è°ƒåº¦ç­–ç•¥
    strategy: Arc<dyn SchedulingStrategy>,
    // QoS ç®¡ç†
    qos_manager: Arc<QosManager>,
    // é¢„æµ‹æ¨¡å‹
    predictor: Arc<ResourcePredictor>,
}

#[async_trait]
pub trait SchedulingStrategy: Send + Sync {
    async fn select_node(
        &self,
        requirements: &ResourceRequirements,
        available_nodes: &[NodeInfo],
    ) -> Result<NodeId, SchedulerError>;
}

pub struct BinPackingStrategy;
pub struct SpreadStrategy;
pub struct AffinityStrategy {
    affinity_rules: Vec<AffinityRule>,
}

#[derive(Debug, Clone)]
pub struct ResourceRequirements {
    pub cpu_cores: f32,
    pub memory_mb: u32,
    pub gpu_count: Option<u32>,
    pub network_bandwidth_mbps: Option<u32>,
    pub storage_gb: Option<u32>,
    pub constraints: Vec<Constraint>,
}

impl ResourceScheduler {
    /// ä¸ºæ²™ç®±åˆ†é…èµ„æº
    pub async fn schedule_sandbox(
        &self,
        requirements: &ResourceRequirements,
    ) -> Result<SchedulingDecision, SchedulerError> {
        // è·å–å¯ç”¨èŠ‚ç‚¹
        let available_nodes = self.node_manager.get_healthy_nodes().await?;
        
        // è¿‡æ»¤æ»¡è¶³è¦æ±‚çš„èŠ‚ç‚¹
        let suitable_nodes = self.filter_suitable_nodes(&available_nodes, requirements)?;
        
        if suitable_nodes.is_empty() {
            return Err(SchedulerError::InsufficientResources);
        }
        
        // ä½¿ç”¨ç­–ç•¥é€‰æ‹©æœ€ä½³èŠ‚ç‚¹
        let selected_node = self.strategy.select_node(requirements, &suitable_nodes).await?;
        
        // é¢„ç•™èµ„æº
        let reservation = self.resource_tracker
            .reserve(selected_node.clone(), requirements)
            .await?;
        
        // é…ç½® QoS
        let qos_config = self.qos_manager
            .configure_qos(&selected_node, requirements)
            .await?;
        
        Ok(SchedulingDecision {
            node_id: selected_node,
            reservation_id: reservation.id,
            qos_config,
        })
    }
    
    /// åŠ¨æ€è°ƒæ•´èµ„æºåˆ†é…
    pub async fn rebalance(&self) -> Result<Vec<Migration>, SchedulerError> {
        let current_state = self.resource_tracker.get_cluster_state().await?;
        let predicted_load = self.predictor.predict_load(Duration::from_mins(15)).await?;
        
        // è®¡ç®—æœ€ä¼˜åˆ†é…
        let optimal_allocation = self.calculate_optimal_allocation(
            &current_state,
            &predicted_load,
        )?;
        
        // ç”Ÿæˆè¿ç§»è®¡åˆ’
        let migrations = self.plan_migrations(&current_state, &optimal_allocation)?;
        
        Ok(migrations)
    }
}
```

### 15. CLI å·¥å…·å¥—ä»¶ â­â­â­â­

å®Œæ•´çš„å‘½ä»¤è¡Œå·¥å…·æ”¯æŒã€‚

#### è®¾è®¡ç»“æ„

```bash
soulbox
â”œâ”€â”€ init          # åˆå§‹åŒ–é¡¹ç›®
â”œâ”€â”€ template      # æ¨¡æ¿ç®¡ç†
â”‚   â”œâ”€â”€ build     # æ„å»ºæ¨¡æ¿
â”‚   â”œâ”€â”€ list      # åˆ—å‡ºæ¨¡æ¿
â”‚   â””â”€â”€ push      # æ¨é€æ¨¡æ¿
â”œâ”€â”€ sandbox       # æ²™ç®±ç®¡ç†
â”‚   â”œâ”€â”€ create    # åˆ›å»ºæ²™ç®±
â”‚   â”œâ”€â”€ list      # åˆ—å‡ºæ²™ç®±
â”‚   â”œâ”€â”€ destroy   # é”€æ¯æ²™ç®±
â”‚   â””â”€â”€ info      # æ²™ç®±ä¿¡æ¯
â”œâ”€â”€ exec          # æ‰§è¡Œå‘½ä»¤
â”œâ”€â”€ cp            # å¤åˆ¶æ–‡ä»¶
â”œâ”€â”€ logs          # æŸ¥çœ‹æ—¥å¿—
â””â”€â”€ config        # é…ç½®ç®¡ç†
```

#### Rust å®ç°

```rust
use clap::{Parser, Subcommand};

#[derive(Parser)]
#[clap(name = "soulbox")]
#[clap(about = "SoulBox CLI - Secure code execution sandbox", version)]
pub struct Cli {
    #[clap(subcommand)]
    pub command: Commands,
    
    #[clap(short, long, global = true)]
    pub config: Option<PathBuf>,
    
    #[clap(short, long, global = true)]
    pub verbose: bool,
}

#[derive(Subcommand)]
pub enum Commands {
    /// Initialize a new SoulBox project
    Init {
        #[clap(short, long)]
        name: Option<String>,
        
        #[clap(long)]
        template: Option<String>,
    },
    
    /// Manage templates
    Template {
        #[clap(subcommand)]
        command: TemplateCommands,
    },
    
    /// Manage sandboxes
    Sandbox {
        #[clap(subcommand)]
        command: SandboxCommands,
    },
    
    /// Execute command in sandbox
    Exec {
        sandbox_id: String,
        command: Vec<String>,
        
        #[clap(short, long)]
        interactive: bool,
    },
    
    /// Copy files to/from sandbox
    Cp {
        source: String,
        destination: String,
        
        #[clap(short, long)]
        recursive: bool,
    },
    
    /// View sandbox logs
    Logs {
        sandbox_id: String,
        
        #[clap(short, long)]
        follow: bool,
        
        #[clap(short, long)]
        tail: Option<usize>,
    },
}

/// CLI åº”ç”¨ä¸»é€»è¾‘
pub async fn run_cli() -> Result<(), CliError> {
    let cli = Cli::parse();
    
    // åˆå§‹åŒ–é…ç½®
    let config = load_config(cli.config)?;
    
    // è®¾ç½®æ—¥å¿—
    if cli.verbose {
        env_logger::Builder::from_env(env_logger::Env::default())
            .filter_level(log::LevelFilter::Debug)
            .init();
    }
    
    // æ‰§è¡Œå‘½ä»¤
    match cli.command {
        Commands::Init { name, template } => {
            cmd_init(name, template).await?;
        }
        Commands::Template { command } => {
            handle_template_command(command, &config).await?;
        }
        Commands::Sandbox { command } => {
            handle_sandbox_command(command, &config).await?;
        }
        Commands::Exec { sandbox_id, command, interactive } => {
            cmd_exec(&sandbox_id, command, interactive, &config).await?;
        }
        Commands::Cp { source, destination, recursive } => {
            cmd_copy(&source, &destination, recursive, &config).await?;
        }
        Commands::Logs { sandbox_id, follow, tail } => {
            cmd_logs(&sandbox_id, follow, tail, &config).await?;
        }
    }
    
    Ok(())
}
```

### 16. å®æ—¶æ—¥å¿—æµå’Œè°ƒè¯• â­â­â­â­

æ”¯æŒå®æ—¶æ—¥å¿—æŸ¥çœ‹å’Œè¿œç¨‹è°ƒè¯•ã€‚

#### Rust å®ç°

```rust
use tokio::sync::broadcast;
use futures::stream::{Stream, StreamExt};

pub struct LogStreamer {
    // æ—¥å¿—ç¼“å†²åŒº
    buffer: Arc<Mutex<CircularBuffer<LogEntry>>>,
    // å¹¿æ’­é€šé“
    broadcaster: broadcast::Sender<LogEntry>,
    // æ—¥å¿—è¿‡æ»¤å™¨
    filters: Arc<Mutex<Vec<LogFilter>>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LogEntry {
    pub timestamp: DateTime<Utc>,
    pub level: LogLevel,
    pub source: LogSource,
    pub message: String,
    pub metadata: serde_json::Value,
}

#[derive(Debug, Clone)]
pub enum LogSource {
    Sandbox(SandboxId),
    System,
    Process(u32),
    Container(String),
}

impl LogStreamer {
    /// è®¢é˜…æ—¥å¿—æµ
    pub fn subscribe(
        &self,
        filter: Option<LogFilter>,
    ) -> impl Stream<Item = LogEntry> {
        let mut receiver = self.broadcaster.subscribe();
        let filter = filter.unwrap_or_default();
        
        async_stream::stream! {
            while let Ok(entry) = receiver.recv().await {
                if filter.matches(&entry) {
                    yield entry;
                }
            }
        }
    }
    
    /// æµå¼ä¼ è¾“æ—¥å¿—åˆ° WebSocket
    pub async fn stream_to_websocket(
        &self,
        ws: WebSocketStream,
        filter: Option<LogFilter>,
    ) -> Result<(), StreamError> {
        let mut log_stream = self.subscribe(filter);
        let (mut tx, mut rx) = ws.split();
        
        // å‘é€å†å²æ—¥å¿—
        let history = self.get_recent_logs(100).await?;
        for entry in history {
            let msg = Message::text(serde_json::to_string(&entry)?);
            tx.send(msg).await?;
        }
        
        // æµå¼å‘é€æ–°æ—¥å¿—
        while let Some(entry) = log_stream.next().await {
            let msg = Message::text(serde_json::to_string(&entry)?);
            if tx.send(msg).await.is_err() {
                break;
            }
        }
        
        Ok(())
    }
}

/// è¿œç¨‹è°ƒè¯•æ”¯æŒ
pub struct DebugServer {
    sandboxes: Arc<Mutex<HashMap<SandboxId, DebugSession>>>,
    port: u16,
}

pub struct DebugSession {
    sandbox_id: SandboxId,
    debugger: Box<dyn Debugger>,
    breakpoints: Vec<Breakpoint>,
    watch_expressions: Vec<WatchExpression>,
}

impl DebugServer {
    /// å¯åŠ¨è°ƒè¯•æœåŠ¡å™¨
    pub async fn start(&self) -> Result<(), DebugError> {
        let app = Router::new()
            .route("/debug/:sandbox_id/attach", post(Self::handle_attach))
            .route("/debug/:sandbox_id/breakpoint", post(Self::handle_breakpoint))
            .route("/debug/:sandbox_id/step", post(Self::handle_step))
            .route("/debug/:sandbox_id/continue", post(Self::handle_continue))
            .route("/debug/:sandbox_id/evaluate", post(Self::handle_evaluate))
            .with_state(self.clone());
        
        axum::Server::bind(&([0, 0, 0, 0], self.port).into())
            .serve(app.into_make_service())
            .await?;
        
        Ok(())
    }
}
```

### 17. é«˜çº§ç½‘ç»œç®¡ç† â­â­â­â­

å®Œæ•´çš„è™šæ‹Ÿç½‘ç»œå’Œæµé‡æ§åˆ¶ã€‚

#### Rust å®ç°

```rust
use nix::sys::socket::{socket, AddressFamily, SockType, SockFlag};

pub struct NetworkManager {
    // è™šæ‹Ÿç½‘ç»œæ‹“æ‰‘
    topology: Arc<Mutex<NetworkTopology>>,
    // æµé‡æ§åˆ¶
    traffic_control: Arc<TrafficControl>,
    // DNS ç®¡ç†
    dns_resolver: Arc<DnsResolver>,
    // é˜²ç«å¢™è§„åˆ™
    firewall: Arc<Firewall>,
}

#[derive(Debug, Clone)]
pub struct NetworkTopology {
    // è™šæ‹Ÿç½‘æ¡¥
    bridges: HashMap<BridgeId, VirtualBridge>,
    // ç½‘ç»œå‘½åç©ºé—´
    namespaces: HashMap<SandboxId, NetworkNamespace>,
    // è·¯ç”±è¡¨
    routing_table: RoutingTable,
}

pub struct TrafficControl {
    // å¸¦å®½é™åˆ¶
    bandwidth_limiter: Arc<Mutex<HashMap<SandboxId, BandwidthLimit>>>,
    // å»¶è¿Ÿæ¨¡æ‹Ÿ
    latency_emulator: Arc<LatencyEmulator>,
    // ä¸¢åŒ…æ¨¡æ‹Ÿ
    packet_loss: Arc<PacketLossEmulator>,
    // QoS é˜Ÿåˆ—
    qos_queues: Arc<Mutex<HashMap<SandboxId, QosQueue>>>,
}

#[derive(Debug, Clone)]
pub struct BandwidthLimit {
    pub ingress_mbps: u32,
    pub egress_mbps: u32,
    pub burst_size: Option<u32>,
}

impl NetworkManager {
    /// ä¸ºæ²™ç®±åˆ›å»ºéš”ç¦»ç½‘ç»œ
    pub async fn create_sandbox_network(
        &self,
        sandbox_id: &SandboxId,
        config: &NetworkConfig,
    ) -> Result<NetworkInfo, NetworkError> {
        // åˆ›å»ºç½‘ç»œå‘½åç©ºé—´
        let netns = self.create_network_namespace(sandbox_id).await?;
        
        // åˆ›å»ºè™šæ‹Ÿç½‘å¡å¯¹
        let (veth_host, veth_sandbox) = self.create_veth_pair(sandbox_id).await?;
        
        // ç§»åŠ¨ç½‘å¡åˆ°å‘½åç©ºé—´
        self.move_interface_to_netns(&veth_sandbox, &netns).await?;
        
        // é…ç½®ç½‘ç»œ
        self.configure_network(&netns, &veth_sandbox, config).await?;
        
        // è®¾ç½®æµé‡æ§åˆ¶
        if let Some(tc) = &config.traffic_control {
            self.apply_traffic_control(sandbox_id, tc).await?;
        }
        
        // é…ç½®é˜²ç«å¢™è§„åˆ™
        if let Some(rules) = &config.firewall_rules {
            self.firewall.apply_rules(sandbox_id, rules).await?;
        }
        
        Ok(NetworkInfo {
            namespace: netns,
            interfaces: vec![veth_sandbox],
            ip_address: config.ip_address.clone(),
        })
    }
    
    /// åº”ç”¨æµé‡æ§åˆ¶
    async fn apply_traffic_control(
        &self,
        sandbox_id: &SandboxId,
        config: &TrafficControlConfig,
    ) -> Result<(), NetworkError> {
        // å¸¦å®½é™åˆ¶
        if let Some(bandwidth) = &config.bandwidth_limit {
            self.traffic_control.bandwidth_limiter
                .lock().await
                .insert(sandbox_id.clone(), bandwidth.clone());
            
            // ä½¿ç”¨ tc å‘½ä»¤é…ç½®
            self.execute_tc_command(&[
                "qdisc", "add", "dev", &format!("veth-{}", sandbox_id),
                "root", "tbf",
                "rate", &format!("{}mbit", bandwidth.egress_mbps),
                "burst", "32kbit",
                "latency", "400ms",
            ]).await?;
        }
        
        // å»¶è¿Ÿæ¨¡æ‹Ÿ
        if let Some(latency) = &config.latency_ms {
            self.execute_tc_command(&[
                "qdisc", "add", "dev", &format!("veth-{}", sandbox_id),
                "root", "netem",
                "delay", &format!("{}ms", latency),
            ]).await?;
        }
        
        Ok(())
    }
}
```

### 18. WebSocket å’Œ PTY æ”¯æŒ â­â­â­â­

äº¤äº’å¼ç»ˆç«¯å’Œå®æ—¶é€šä¿¡ã€‚

#### Rust å®ç°

```rust
use tokio_tungstenite::{WebSocketStream, tungstenite::Message};
use nix::pty::{openpty, OpenptyResult};

pub struct PtyManager {
    // PTY ä¼šè¯ç®¡ç†
    sessions: Arc<Mutex<HashMap<SessionId, PtySession>>>,
    // WebSocket è¿æ¥ç®¡ç†
    connections: Arc<Mutex<HashMap<ConnectionId, WebSocketStream<TcpStream>>>>,
}

pub struct PtySession {
    // ä¼šè¯ ID
    id: SessionId,
    // ä¸»ä» PTY å¯¹
    pty: OpenptyResult,
    // å…³è”çš„æ²™ç®±
    sandbox_id: SandboxId,
    // ä¼šè¯é…ç½®
    config: PtyConfig,
    // è¾“å…¥è¾“å‡ºç¼“å†²
    buffer: Arc<Mutex<CircularBuffer>>,
}

#[derive(Debug, Clone)]
pub struct PtyConfig {
    pub rows: u16,
    pub cols: u16,
    pub term: String,
    pub shell: PathBuf,
    pub env: HashMap<String, String>,
}

impl PtyManager {
    /// åˆ›å»ºæ–°çš„ PTY ä¼šè¯
    pub async fn create_session(
        &self,
        sandbox_id: &SandboxId,
        config: PtyConfig,
    ) -> Result<SessionInfo, PtyError> {
        // æ‰“å¼€ PTY
        let pty = openpty(None, None)?;
        
        // è®¾ç½®ç»ˆç«¯å¤§å°
        self.set_terminal_size(&pty, config.rows, config.cols)?;
        
        // åœ¨æ²™ç®±ä¸­å¯åŠ¨ shell
        let sandbox = self.get_sandbox(sandbox_id).await?;
        let process = sandbox.spawn_with_pty(
            &config.shell,
            pty.slave,
            config.env.clone(),
        ).await?;
        
        // åˆ›å»ºä¼šè¯
        let session = PtySession {
            id: SessionId::new(),
            pty,
            sandbox_id: sandbox_id.clone(),
            config,
            buffer: Arc::new(Mutex::new(CircularBuffer::new(1024 * 1024))),
        };
        
        let session_id = session.id.clone();
        self.sessions.lock().await.insert(session_id.clone(), session);
        
        // å¯åŠ¨ I/O è½¬å‘
        self.start_io_forwarding(session_id.clone()).await?;
        
        Ok(SessionInfo {
            session_id,
            websocket_url: format!("/ws/pty/{}", session_id),
        })
    }
    
    /// å¤„ç† WebSocket è¿æ¥
    pub async fn handle_websocket(
        &self,
        ws: WebSocketStream<TcpStream>,
        session_id: SessionId,
    ) -> Result<(), PtyError> {
        let (ws_tx, mut ws_rx) = ws.split();
        let ws_tx = Arc::new(Mutex::new(ws_tx));
        
        let session = self.sessions.lock().await
            .get(&session_id)
            .cloned()
            .ok_or(PtyError::SessionNotFound)?;
        
        // ä» PTY åˆ° WebSocket
        let pty_to_ws = {
            let ws_tx = ws_tx.clone();
            let master_fd = session.pty.master;
            
            tokio::spawn(async move {
                let mut buffer = [0u8; 4096];
                let mut master = unsafe { File::from_raw_fd(master_fd) };
                
                loop {
                    match master.read(&mut buffer).await {
                        Ok(0) => break,
                        Ok(n) => {
                            let data = &buffer[..n];
                            let msg = Message::Binary(data.to_vec());
                            
                            if ws_tx.lock().await.send(msg).await.is_err() {
                                break;
                            }
                        }
                        Err(_) => break,
                    }
                }
            })
        };
        
        // ä» WebSocket åˆ° PTY
        let ws_to_pty = {
            let master_fd = session.pty.master;
            
            tokio::spawn(async move {
                let mut master = unsafe { File::from_raw_fd(master_fd) };
                
                while let Some(Ok(msg)) = ws_rx.next().await {
                    match msg {
                        Message::Binary(data) | Message::Text(data) => {
                            if master.write_all(&data).await.is_err() {
                                break;
                            }
                        }
                        Message::Close(_) => break,
                        _ => {}
                    }
                }
            })
        };
        
        // ç­‰å¾…ä»»ä¸€æ–¹å‘ç»“æŸ
        tokio::select! {
            _ = pty_to_ws => {},
            _ = ws_to_pty => {},
        }
        
        // æ¸…ç†ä¼šè¯
        self.sessions.lock().await.remove(&session_id);
        
        Ok(())
    }
    
    /// è°ƒæ•´ç»ˆç«¯å¤§å°
    pub async fn resize_pty(
        &self,
        session_id: &SessionId,
        rows: u16,
        cols: u16,
    ) -> Result<(), PtyError> {
        let sessions = self.sessions.lock().await;
        let session = sessions.get(session_id)
            .ok_or(PtyError::SessionNotFound)?;
        
        self.set_terminal_size(&session.pty, rows, cols)?;
        
        Ok(())
    }
}
```

### 19. å¿«ç…§å’Œæ£€æŸ¥ç‚¹ â­â­â­

æ”¯æŒæ²™ç®±çŠ¶æ€çš„ä¿å­˜å’Œæ¢å¤ã€‚

#### Rust å®ç°

```rust
use criu::{CriuClient, CriuOptions};

pub struct SnapshotManager {
    // å¿«ç…§å­˜å‚¨åç«¯
    storage: Arc<dyn SnapshotStorage>,
    // CRIU å®¢æˆ·ç«¯
    criu_client: CriuClient,
    // å‹ç¼©é…ç½®
    compression: CompressionConfig,
    // å¢é‡å¿«ç…§æ”¯æŒ
    incremental: bool,
}

#[derive(Debug, Clone)]
pub struct Snapshot {
    pub id: SnapshotId,
    pub sandbox_id: SandboxId,
    pub created_at: DateTime<Utc>,
    pub size_bytes: u64,
    pub metadata: SnapshotMetadata,
    pub parent_id: Option<SnapshotId>,
}

#[derive(Debug, Clone)]
pub struct SnapshotMetadata {
    pub description: Option<String>,
    pub tags: Vec<String>,
    pub sandbox_state: SandboxState,
    pub memory_pages: u64,
    pub file_descriptors: Vec<FileDescriptor>,
}

#[async_trait]
pub trait SnapshotStorage: Send + Sync {
    async fn save(&self, snapshot: &Snapshot, data: SnapshotData) -> Result<(), StorageError>;
    async fn load(&self, id: &SnapshotId) -> Result<(Snapshot, SnapshotData), StorageError>;
    async fn delete(&self, id: &SnapshotId) -> Result<(), StorageError>;
    async fn list(&self, filter: Option<SnapshotFilter>) -> Result<Vec<Snapshot>, StorageError>;
}

impl SnapshotManager {
    /// åˆ›å»ºæ²™ç®±å¿«ç…§
    pub async fn create_snapshot(
        &self,
        sandbox: &Sandbox,
        options: SnapshotOptions,
    ) -> Result<Snapshot, SnapshotError> {
        // å‡†å¤‡å¿«ç…§ç›®å½•
        let snapshot_dir = tempdir()?;
        let snapshot_path = snapshot_dir.path();
        
        // æš‚åœæ²™ç®±
        sandbox.pause().await?;
        
        // ä½¿ç”¨ CRIU åˆ›å»ºæ£€æŸ¥ç‚¹
        let criu_opts = CriuOptions {
            images_dir: snapshot_path.to_path_buf(),
            leave_running: options.leave_running,
            shell_job: true,
            tcp_established: true,
            ext_unix_sk: true,
            file_locks: true,
            track_mem: self.incremental,
            parent_img: options.parent_id.map(|id| id.to_string()),
        };
        
        self.criu_client.dump(sandbox.pid(), criu_opts).await?;
        
        // æ•è·æ–‡ä»¶ç³»ç»ŸçŠ¶æ€
        let fs_snapshot = self.capture_filesystem(sandbox).await?;
        
        // æ”¶é›†å…ƒæ•°æ®
        let metadata = self.collect_metadata(sandbox, snapshot_path).await?;
        
        // åˆ›å»ºå¿«ç…§æ•°æ®
        let snapshot_data = SnapshotData {
            memory_image: self.read_memory_image(snapshot_path).await?,
            filesystem: fs_snapshot,
            metadata: metadata.clone(),
        };
        
        // å‹ç¼©æ•°æ®
        let compressed_data = self.compress_snapshot_data(snapshot_data).await?;
        
        // åˆ›å»ºå¿«ç…§è®°å½•
        let snapshot = Snapshot {
            id: SnapshotId::new(),
            sandbox_id: sandbox.id().clone(),
            created_at: Utc::now(),
            size_bytes: compressed_data.len() as u64,
            metadata,
            parent_id: options.parent_id,
        };
        
        // ä¿å­˜åˆ°å­˜å‚¨
        self.storage.save(&snapshot, compressed_data).await?;
        
        // æ¢å¤æ²™ç®±è¿è¡Œ
        if !options.leave_running {
            sandbox.resume().await?;
        }
        
        Ok(snapshot)
    }
    
    /// ä»å¿«ç…§æ¢å¤æ²™ç®±
    pub async fn restore_snapshot(
        &self,
        snapshot_id: &SnapshotId,
        options: RestoreOptions,
    ) -> Result<Sandbox, SnapshotError> {
        // åŠ è½½å¿«ç…§
        let (snapshot, data) = self.storage.load(snapshot_id).await?;
        
        // è§£å‹æ•°æ®
        let snapshot_data = self.decompress_snapshot_data(data).await?;
        
        // å‡†å¤‡æ¢å¤ç›®å½•
        let restore_dir = tempdir()?;
        let restore_path = restore_dir.path();
        
        // å†™å…¥å†…å­˜é•œåƒ
        self.write_memory_image(restore_path, &snapshot_data.memory_image).await?;
        
        // æ¢å¤æ–‡ä»¶ç³»ç»Ÿ
        let sandbox_root = self.restore_filesystem(&snapshot_data.filesystem).await?;
        
        // ä½¿ç”¨ CRIU æ¢å¤
        let criu_opts = CriuOptions {
            images_dir: restore_path.to_path_buf(),
            shell_job: true,
            tcp_established: true,
            ext_unix_sk: true,
            file_locks: true,
            restore_detached: true,
            new_namespace: options.new_namespace,
        };
        
        let pid = self.criu_client.restore(criu_opts).await?;
        
        // åˆ›å»ºæ–°çš„æ²™ç®±å®ä¾‹
        let sandbox = Sandbox::from_restored(
            options.sandbox_id.unwrap_or_else(SandboxId::new),
            pid,
            sandbox_root,
            snapshot.metadata.sandbox_state,
        )?;
        
        Ok(sandbox)
    }
}
```

### 20. åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ â­â­â­

æ”¯æŒè·¨èŠ‚ç‚¹çš„æ–‡ä»¶å…±äº«å’ŒåŒæ­¥ã€‚

#### Rust å®ç°

```rust
use raft::{Config as RaftConfig, Raft, Storage};

pub struct DistributedFS {
    // èŠ‚ç‚¹ ID
    node_id: NodeId,
    // åˆ†ç‰‡ç®¡ç†
    shard_manager: Arc<ShardManager>,
    // å¤åˆ¶ç­–ç•¥
    replication: Arc<ReplicationStrategy>,
    // ä¸€è‡´æ€§åè®®
    raft: Arc<Mutex<Raft<FileSystemStateMachine>>>,
    // å…ƒæ•°æ®å­˜å‚¨
    metadata_store: Arc<MetadataStore>,
    // å¯¹è±¡å­˜å‚¨
    object_store: Arc<dyn ObjectStore>,
}

#[derive(Debug, Clone)]
pub struct FileMetadata {
    pub path: PathBuf,
    pub size: u64,
    pub chunks: Vec<ChunkInfo>,
    pub permissions: Permissions,
    pub created_at: DateTime<Utc>,
    pub modified_at: DateTime<Utc>,
    pub replication_factor: u8,
}

#[derive(Debug, Clone)]
pub struct ChunkInfo {
    pub id: ChunkId,
    pub offset: u64,
    pub size: u32,
    pub checksum: [u8; 32],
    pub replicas: Vec<NodeId>,
}

impl DistributedFS {
    /// å†™å…¥æ–‡ä»¶
    pub async fn write_file(
        &self,
        path: &Path,
        data: impl AsyncRead,
        options: WriteOptions,
    ) -> Result<FileMetadata, DFSError> {
        // åˆ†å—
        let chunks = self.split_into_chunks(data, options.chunk_size).await?;
        
        // ä¸ºæ¯ä¸ªå—é€‰æ‹©å­˜å‚¨èŠ‚ç‚¹
        let chunk_placement = self.shard_manager
            .place_chunks(&chunks, options.replication_factor)
            .await?;
        
        // å¹¶è¡Œå†™å…¥å—
        let write_futures = chunks.iter().zip(chunk_placement.iter())
            .map(|(chunk, nodes)| {
                self.write_chunk(chunk, nodes)
            });
        
        let chunk_infos = futures::future::try_join_all(write_futures).await?;
        
        // åˆ›å»ºæ–‡ä»¶å…ƒæ•°æ®
        let metadata = FileMetadata {
            path: path.to_path_buf(),
            size: chunks.iter().map(|c| c.len() as u64).sum(),
            chunks: chunk_infos,
            permissions: options.permissions,
            created_at: Utc::now(),
            modified_at: Utc::now(),
            replication_factor: options.replication_factor,
        };
        
        // é€šè¿‡ Raft æäº¤å…ƒæ•°æ®
        self.commit_metadata(&metadata).await?;
        
        Ok(metadata)
    }
    
    /// è¯»å–æ–‡ä»¶
    pub async fn read_file(
        &self,
        path: &Path,
    ) -> Result<impl AsyncRead, DFSError> {
        // è·å–æ–‡ä»¶å…ƒæ•°æ®
        let metadata = self.metadata_store.get(path).await?
            .ok_or_else(|| DFSError::FileNotFound)?;
        
        // åˆ›å»ºå—è¯»å–æµ
        let chunk_streams = metadata.chunks.iter()
            .map(|chunk| self.read_chunk(chunk));
        
        // åˆå¹¶å—æµ
        Ok(ChunkStream::new(chunk_streams))
    }
    
    /// å¤„ç†èŠ‚ç‚¹æ•…éšœ
    pub async fn handle_node_failure(&self, failed_node: &NodeId) -> Result<(), DFSError> {
        // æ‰¾åˆ°å—å½±å“çš„å—
        let affected_chunks = self.metadata_store
            .find_chunks_on_node(failed_node)
            .await?;
        
        // é‡æ–°å¤åˆ¶å—
        for chunk_id in affected_chunks {
            self.replicate_chunk(&chunk_id).await?;
        }
        
        Ok(())
    }
    
    /// å—å¤åˆ¶
    async fn replicate_chunk(&self, chunk_id: &ChunkId) -> Result<(), DFSError> {
        let chunk_info = self.metadata_store.get_chunk(chunk_id).await?;
        
        // æ‰¾åˆ°å¥åº·çš„å‰¯æœ¬
        let healthy_replicas = self.find_healthy_replicas(&chunk_info.replicas).await?;
        
        if healthy_replicas.is_empty() {
            return Err(DFSError::DataLoss);
        }
        
        // ä»å¥åº·å‰¯æœ¬è¯»å–æ•°æ®
        let chunk_data = self.read_chunk_from_node(
            chunk_id,
            &healthy_replicas[0],
        ).await?;
        
        // é€‰æ‹©æ–°èŠ‚ç‚¹
        let new_nodes = self.shard_manager
            .select_nodes_for_replication(1, &chunk_info.replicas)
            .await?;
        
        // å†™å…¥æ–°å‰¯æœ¬
        self.write_chunk_to_nodes(&chunk_data, &new_nodes).await?;
        
        Ok(())
    }
}
```

### 21. å¤šç§Ÿæˆ·æ”¯æŒ â­â­â­

ä¼ä¸šçº§å¤šç§Ÿæˆ·éš”ç¦»å’Œç®¡ç†ã€‚

#### Rust å®ç°

```rust
pub struct TenantManager {
    // ç§Ÿæˆ·æ³¨å†Œè¡¨
    tenants: Arc<Mutex<HashMap<TenantId, Tenant>>>,
    // ç§Ÿæˆ·éš”ç¦»
    isolation: Arc<TenantIsolation>,
    // é…é¢ç®¡ç†
    quota_manager: Arc<QuotaManager>,
    // è®¡è´¹ç³»ç»Ÿ
    billing: Arc<BillingSystem>,
    // å®¡è®¡æ—¥å¿—
    audit_logger: Arc<AuditLogger>,
}

#[derive(Debug, Clone)]
pub struct Tenant {
    pub id: TenantId,
    pub name: String,
    pub status: TenantStatus,
    pub config: TenantConfig,
    pub quota: TenantQuota,
    pub created_at: DateTime<Utc>,
}

#[derive(Debug, Clone)]
pub struct TenantQuota {
    pub max_sandboxes: usize,
    pub max_concurrent_sandboxes: usize,
    pub max_cpu_cores: f32,
    pub max_memory_gb: u32,
    pub max_storage_gb: u32,
    pub network_bandwidth_mbps: u32,
    pub max_templates: usize,
}

#[derive(Debug, Clone)]
pub struct TenantIsolation {
    // ç½‘ç»œéš”ç¦»ç­–ç•¥
    pub network_policy: NetworkIsolationPolicy,
    // å­˜å‚¨éš”ç¦»
    pub storage_isolation: StorageIsolationLevel,
    // è®¡ç®—èµ„æºéš”ç¦»
    pub compute_isolation: ComputeIsolationLevel,
}

impl TenantManager {
    /// åˆ›å»ºæ–°ç§Ÿæˆ·
    pub async fn create_tenant(
        &self,
        request: CreateTenantRequest,
    ) -> Result<Tenant, TenantError> {
        // éªŒè¯è¯·æ±‚
        self.validate_tenant_request(&request)?;
        
        // ç”Ÿæˆç§Ÿæˆ· ID
        let tenant_id = TenantId::new();
        
        // åˆ›å»ºç§Ÿæˆ·
        let tenant = Tenant {
            id: tenant_id.clone(),
            name: request.name,
            status: TenantStatus::Active,
            config: request.config,
            quota: request.quota,
            created_at: Utc::now(),
        };
        
        // è®¾ç½®èµ„æºéš”ç¦»
        self.isolation.setup_tenant_isolation(&tenant).await?;
        
        // åˆå§‹åŒ–é…é¢
        self.quota_manager.initialize_tenant_quota(&tenant).await?;
        
        // åˆ›å»ºè®¡è´¹è´¦æˆ·
        self.billing.create_account(&tenant).await?;
        
        // è®°å½•å®¡è®¡æ—¥å¿—
        self.audit_logger.log(AuditEvent {
            timestamp: Utc::now(),
            tenant_id: Some(tenant_id.clone()),
            action: AuditAction::TenantCreated,
            actor: request.created_by,
            details: json!({ "tenant_name": tenant.name }),
        }).await?;
        
        // ä¿å­˜ç§Ÿæˆ·
        self.tenants.lock().await.insert(tenant_id, tenant.clone());
        
        Ok(tenant)
    }
    
    /// æ£€æŸ¥ç§Ÿæˆ·é…é¢
    pub async fn check_quota(
        &self,
        tenant_id: &TenantId,
        resource: &ResourceRequest,
    ) -> Result<(), QuotaError> {
        let usage = self.quota_manager.get_usage(tenant_id).await?;
        let quota = self.get_tenant_quota(tenant_id).await?;
        
        // æ£€æŸ¥å„é¡¹èµ„æº
        if usage.sandbox_count + 1 > quota.max_sandboxes {
            return Err(QuotaError::SandboxLimitExceeded);
        }
        
        if usage.cpu_cores + resource.cpu_cores > quota.max_cpu_cores {
            return Err(QuotaError::CpuLimitExceeded);
        }
        
        if usage.memory_gb + resource.memory_gb > quota.max_memory_gb {
            return Err(QuotaError::MemoryLimitExceeded);
        }
        
        Ok(())
    }
    
    /// ç§Ÿæˆ·èµ„æºä½¿ç”¨æŠ¥å‘Š
    pub async fn generate_usage_report(
        &self,
        tenant_id: &TenantId,
        period: DateRange,
    ) -> Result<UsageReport, TenantError> {
        let usage_data = self.billing
            .get_usage_data(tenant_id, period)
            .await?;
        
        let report = UsageReport {
            tenant_id: tenant_id.clone(),
            period,
            total_sandbox_hours: usage_data.sandbox_hours,
            average_cpu_usage: usage_data.avg_cpu,
            peak_memory_gb: usage_data.peak_memory,
            total_storage_gb_hours: usage_data.storage_hours,
            network_transfer_gb: usage_data.network_transfer,
            estimated_cost: self.billing.calculate_cost(&usage_data).await?,
        };
        
        Ok(report)
    }
}
```

### 22. å®¡è®¡å’Œåˆè§„ â­â­â­

å®Œæ•´çš„å®¡è®¡æ—¥å¿—å’Œåˆè§„æ€§æ”¯æŒã€‚

#### Rust å®ç°

```rust
use ring::digest::{digest, SHA256};

pub struct AuditLogger {
    // å®¡è®¡äº‹ä»¶å­˜å‚¨
    event_store: Arc<dyn AuditEventStore>,
    // åˆè§„ç­–ç•¥
    compliance_policies: Arc<Mutex<Vec<CompliancePolicy>>>,
    // äº‹ä»¶ç­¾å
    signer: Arc<EventSigner>,
    // äº‹ä»¶æµ
    event_stream: broadcast::Sender<AuditEvent>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AuditEvent {
    pub id: EventId,
    pub timestamp: DateTime<Utc>,
    pub tenant_id: Option<TenantId>,
    pub user_id: Option<UserId>,
    pub action: AuditAction,
    pub resource: AuditResource,
    pub result: AuditResult,
    pub ip_address: Option<IpAddr>,
    pub user_agent: Option<String>,
    pub details: serde_json::Value,
    pub signature: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AuditAction {
    // æ²™ç®±æ“ä½œ
    SandboxCreated,
    SandboxDestroyed,
    SandboxPaused,
    SandboxResumed,
    
    // æ–‡ä»¶æ“ä½œ
    FileUploaded,
    FileDownloaded,
    FileDeleted,
    
    // è®¤è¯äº‹ä»¶
    LoginSuccess,
    LoginFailed,
    TokenCreated,
    TokenRevoked,
    
    // ç®¡ç†æ“ä½œ
    UserCreated,
    UserDeleted,
    PermissionGranted,
    PermissionRevoked,
    
    // åˆè§„äº‹ä»¶
    PolicyViolation,
    DataExport,
    ConfigChange,
}

#[derive(Debug, Clone)]
pub struct CompliancePolicy {
    pub id: PolicyId,
    pub name: String,
    pub rules: Vec<ComplianceRule>,
    pub actions: Vec<ComplianceAction>,
}

impl AuditLogger {
    /// è®°å½•å®¡è®¡äº‹ä»¶
    pub async fn log(&self, mut event: AuditEvent) -> Result<(), AuditError> {
        // è®¾ç½®äº‹ä»¶ ID å’Œæ—¶é—´æˆ³
        event.id = EventId::new();
        if event.timestamp == DateTime::default() {
            event.timestamp = Utc::now();
        }
        
        // ç­¾åäº‹ä»¶
        event.signature = Some(self.signer.sign_event(&event).await?);
        
        // æ£€æŸ¥åˆè§„æ€§
        self.check_compliance(&event).await?;
        
        // å­˜å‚¨äº‹ä»¶
        self.event_store.store(&event).await?;
        
        // å¹¿æ’­äº‹ä»¶
        let _ = self.event_stream.send(event.clone());
        
        Ok(())
    }
    
    /// æŸ¥è¯¢å®¡è®¡æ—¥å¿—
    pub async fn query(
        &self,
        filter: AuditFilter,
    ) -> Result<AuditQueryResult, AuditError> {
        let events = self.event_store.query(&filter).await?;
        
        // éªŒè¯ç­¾å
        let mut verified_events = Vec::new();
        for event in events {
            if self.signer.verify_event(&event).await? {
                verified_events.push(event);
            } else {
                warn!("Audit event {} has invalid signature", event.id);
            }
        }
        
        Ok(AuditQueryResult {
            events: verified_events,
            total_count: self.event_store.count(&filter).await?,
        })
    }
    
    /// ç”Ÿæˆåˆè§„æŠ¥å‘Š
    pub async fn generate_compliance_report(
        &self,
        policy_id: &PolicyId,
        period: DateRange,
    ) -> Result<ComplianceReport, AuditError> {
        let policy = self.get_policy(policy_id).await?;
        let events = self.query(AuditFilter {
            time_range: Some(period),
            ..Default::default()
        }).await?;
        
        let mut violations = Vec::new();
        let mut compliance_score = 100.0;
        
        for rule in &policy.rules {
            let rule_violations = self.check_rule_violations(&rule, &events.events)?;
            if !rule_violations.is_empty() {
                compliance_score -= rule.penalty_weight;
                violations.extend(rule_violations);
            }
        }
        
        Ok(ComplianceReport {
            policy_id: policy_id.clone(),
            period,
            compliance_score: compliance_score.max(0.0),
            violations,
            recommendations: self.generate_recommendations(&violations),
            generated_at: Utc::now(),
        })
    }
    
    /// å¯¼å‡ºå®¡è®¡æ—¥å¿—ï¼ˆç”¨äºå¤–éƒ¨å®¡è®¡ï¼‰
    pub async fn export_logs(
        &self,
        filter: AuditFilter,
        format: ExportFormat,
    ) -> Result<Vec<u8>, AuditError> {
        let events = self.query(filter).await?;
        
        match format {
            ExportFormat::Json => {
                Ok(serde_json::to_vec_pretty(&events)?)
            }
            ExportFormat::Csv => {
                let mut wtr = csv::Writer::new(Vec::new());
                for event in events.events {
                    wtr.serialize(&event)?;
                }
                Ok(wtr.into_inner()?)
            }
            ExportFormat::Syslog => {
                let mut output = Vec::new();
                for event in events.events {
                    writeln!(output, "{}", self.format_syslog(&event)?)?;
                }
                Ok(output)
            }
        }
    }
}

/// äº‹ä»¶ç­¾åå™¨
pub struct EventSigner {
    signing_key: Arc<SigningKey>,
}

impl EventSigner {
    /// ç­¾åäº‹ä»¶
    async fn sign_event(&self, event: &AuditEvent) -> Result<String, SignError> {
        let event_bytes = serde_json::to_vec(event)?;
        let signature = self.signing_key.sign(&event_bytes);
        Ok(base64::encode(signature))
    }
    
    /// éªŒè¯ç­¾å
    async fn verify_event(&self, event: &AuditEvent) -> Result<bool, SignError> {
        if let Some(signature) = &event.signature {
            let mut event_copy = event.clone();
            event_copy.signature = None;
            
            let event_bytes = serde_json::to_vec(&event_copy)?;
            let signature_bytes = base64::decode(signature)?;
            
            Ok(self.signing_key.verify(&event_bytes, &signature_bytes).is_ok())
        } else {
            Ok(false)
        }
    }
}
```

---

## å®æ–½ä¼˜å…ˆçº§å’Œæ—¶é—´è¡¨

### ä¼˜å…ˆçº§åˆ†ç»„

#### P0 - å¿…é¡»ç«‹å³å®æ–½ï¼ˆ1-4 å‘¨ï¼‰
1. âœ… å¥åº·æ£€æŸ¥ç«¯ç‚¹
2. âœ… æ–‡ä»¶ç­¾åå’Œå®‰å…¨ URL
3. âœ… ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
4. â­ å¤šå±‚è®¤è¯æœºåˆ¶
5. â­ ç»†ç²’åº¦æƒé™æ§åˆ¶ (RBAC)

#### P1 - æ ¸å¿ƒåŠŸèƒ½å¢å¼ºï¼ˆ5-12 å‘¨ï¼‰
6. âœ… è‡ªåŠ¨æš‚åœåŠŸèƒ½
7. âœ… å‘½ä»¤éƒ¨åˆ†è¾“å‡ºè·å–
8. âœ… è¿æ¥é‡å®šå‘æ”¯æŒ
9. âœ… æ²™ç®±åˆ·æ–°æœºåˆ¶
10. âœ… æ²™ç®±æŒ‡æ ‡è¯¦ç»†ä¿¡æ¯
11. â­ æ™ºèƒ½æ²™ç®±æ± ç®¡ç†
12. â­ åŠ¨æ€èµ„æºè°ƒåº¦å™¨
13. â­ CLI å·¥å…·å¥—ä»¶
14. â­ å®æ—¶æ—¥å¿—æµå’Œè°ƒè¯•

#### P2 - é«˜çº§åŠŸèƒ½ï¼ˆ13-20 å‘¨ï¼‰
15. âœ… æ¨¡æ¿æ„å»ºæ—¥å¿—æµ
16. âœ… èŠ‚ç‚¹å¥åº·çŠ¶æ€
17. â­ é«˜çº§ç½‘ç»œç®¡ç†
18. â­ WebSocket å’Œ PTY æ”¯æŒ
19. â­ å¿«ç…§å’Œæ£€æŸ¥ç‚¹
20. â­ åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ

#### P3 - ä¼ä¸šåŠŸèƒ½ï¼ˆ21-24 å‘¨ï¼‰
21. â­ å¤šç§Ÿæˆ·æ”¯æŒ
22. â­ å®¡è®¡å’Œåˆè§„

---

## æ€»ç»“

æœ¬æ–‡æ¡£æ•´åˆäº† SoulBox é¡¹ç›®çš„æ‰€æœ‰ 22 ä¸ªç¼ºå¤±åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- åŸæœ‰çš„ 10 ä¸ªåŸºç¡€åŠŸèƒ½è¡¥å……
- æ–°å‘ç°çš„ 12 ä¸ªé«˜çº§åŠŸèƒ½

æ¯ä¸ªåŠŸèƒ½éƒ½æä¾›äº†ï¼š
- è¯¦ç»†çš„è®¾è®¡è¯´æ˜
- å®Œæ•´çš„ Rust å®ç°ä»£ç 
- å®æ–½ä¼˜å…ˆçº§å»ºè®®

è¿™ä»½æ–‡æ¡£å°†ä½œä¸º SoulBox é¡¹ç›®çš„æ ¸å¿ƒå¼€å‘æŒ‡å—ï¼ŒæŒ‡å¯¼åç»­çš„åŠŸèƒ½å®ç°å·¥ä½œã€‚

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0*  
*æœ€åæ›´æ–°: 2024-08*  
*çŠ¶æ€: å¼€å‘å‚è€ƒæ–‡æ¡£*